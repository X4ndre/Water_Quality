{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality\n",
    "The database was taken from kaggle for more references visit: https://www.kaggle.com/datasets/mssmartypants/water-quality?resource=download\n",
    "<br>In this project the objective is to predict if the water is safe or not, so the answer will be:\n",
    "- 0 = not safe\n",
    "- 1 = safe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from collections import Counter\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = df[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(df, label_name):\n",
    "    x = df.drop(label_name, axis=1)\n",
    "    y = df[label_name].copy()\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/waterQuality1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aluminium      False\n",
       "ammonia        False\n",
       "arsenic        False\n",
       "barium         False\n",
       "cadmium        False\n",
       "chloramine     False\n",
       "chromium       False\n",
       "copper         False\n",
       "flouride       False\n",
       "bacteria       False\n",
       "viruses        False\n",
       "lead           False\n",
       "nitrates       False\n",
       "nitrites       False\n",
       "mercury        False\n",
       "perchlorate    False\n",
       "radium         False\n",
       "selenium       False\n",
       "silver         False\n",
       "uranium        False\n",
       "is_safe        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7999 entries, 0 to 7998\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   aluminium    7999 non-null   float64\n",
      " 1   ammonia      7999 non-null   object \n",
      " 2   arsenic      7999 non-null   float64\n",
      " 3   barium       7999 non-null   float64\n",
      " 4   cadmium      7999 non-null   float64\n",
      " 5   chloramine   7999 non-null   float64\n",
      " 6   chromium     7999 non-null   float64\n",
      " 7   copper       7999 non-null   float64\n",
      " 8   flouride     7999 non-null   float64\n",
      " 9   bacteria     7999 non-null   float64\n",
      " 10  viruses      7999 non-null   float64\n",
      " 11  lead         7999 non-null   float64\n",
      " 12  nitrates     7999 non-null   float64\n",
      " 13  nitrites     7999 non-null   float64\n",
      " 14  mercury      7999 non-null   float64\n",
      " 15  perchlorate  7999 non-null   float64\n",
      " 16  radium       7999 non-null   float64\n",
      " 17  selenium     7999 non-null   float64\n",
      " 18  silver       7999 non-null   float64\n",
      " 19  uranium      7999 non-null   float64\n",
      " 20  is_safe      7999 non-null   object \n",
      "dtypes: float64(19), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.65</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.007</td>\n",
       "      <td>37.75</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.32</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.26</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>50.28</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.36</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>24.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0.05</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>14.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.05</td>\n",
       "      <td>24.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.09</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>15.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.04</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>15.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7999 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  \\\n",
       "0          1.65    9.08     0.04    2.85    0.007        0.35      0.83   \n",
       "1          2.32   21.16     0.01    3.31    0.002        5.28      0.68   \n",
       "2          1.01   14.02     0.04    0.58    0.008        4.24      0.53   \n",
       "3          1.36   11.33     0.04    2.96    0.001        7.23      0.03   \n",
       "4          0.92   24.33     0.03    0.20    0.006        2.67      0.69   \n",
       "...         ...     ...      ...     ...      ...         ...       ...   \n",
       "7994       0.05    7.78     0.00    1.95    0.040        0.10      0.03   \n",
       "7995       0.05   24.22     0.02    0.59    0.010        0.45      0.02   \n",
       "7996       0.09    6.85     0.00    0.61    0.030        0.05      0.05   \n",
       "7997       0.01      10     0.01    2.00    0.000        2.00      0.00   \n",
       "7998       0.04    6.85     0.01    0.70    0.030        0.05      0.01   \n",
       "\n",
       "      copper  flouride  bacteria  ...   lead  nitrates  nitrites  mercury  \\\n",
       "0       0.17      0.05      0.20  ...  0.054     16.08      1.13    0.007   \n",
       "1       0.66      0.90      0.65  ...  0.100      2.01      1.93    0.003   \n",
       "2       0.02      0.99      0.05  ...  0.078     14.16      1.11    0.006   \n",
       "3       1.66      1.08      0.71  ...  0.016      1.41      1.29    0.004   \n",
       "4       0.57      0.61      0.13  ...  0.117      6.74      1.11    0.003   \n",
       "...      ...       ...       ...  ...    ...       ...       ...      ...   \n",
       "7994    0.03      1.37      0.00  ...  0.197     14.29      1.00    0.005   \n",
       "7995    0.02      1.48      0.00  ...  0.031     10.27      1.00    0.001   \n",
       "7996    0.02      0.91      0.00  ...  0.182     15.92      1.00    0.000   \n",
       "7997    0.09      0.00      0.00  ...  0.000      0.00      0.00    0.000   \n",
       "7998    0.03      1.00      0.00  ...  0.182     15.92      1.00    0.000   \n",
       "\n",
       "      perchlorate  radium  selenium  silver  uranium  is_safe  \n",
       "0           37.75    6.78      0.08    0.34     0.02        1  \n",
       "1           32.26    3.21      0.08    0.27     0.05        1  \n",
       "2           50.28    7.07      0.07    0.44     0.01        0  \n",
       "3            9.12    1.72      0.02    0.45     0.05        1  \n",
       "4           16.90    2.41      0.02    0.06     0.02        1  \n",
       "...           ...     ...       ...     ...      ...      ...  \n",
       "7994         3.57    2.13      0.09    0.06     0.03        1  \n",
       "7995         1.48    1.11      0.09    0.10     0.08        1  \n",
       "7996         1.35    4.84      0.00    0.04     0.05        1  \n",
       "7997         0.00    0.00      0.00    0.00     0.00        1  \n",
       "7998         1.35    4.84      0.00    0.04     0.05        1  \n",
       "\n",
       "[7999 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"is_safe != 0 and is_safe != 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.65</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.007</td>\n",
       "      <td>37.75</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.32</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.26</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>50.28</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.36</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>24.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.94</td>\n",
       "      <td>14.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.006</td>\n",
       "      <td>27.17</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.36</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.007</td>\n",
       "      <td>45.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.93</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.001</td>\n",
       "      <td>53.35</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.60</td>\n",
       "      <td>24.58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167</td>\n",
       "      <td>14.66</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.43</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22</td>\n",
       "      <td>16.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.007</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  copper  \\\n",
       "0       1.65    9.08     0.04    2.85    0.007        0.35      0.83    0.17   \n",
       "1       2.32   21.16     0.01    3.31    0.002        5.28      0.68    0.66   \n",
       "2       1.01   14.02     0.04    0.58    0.008        4.24      0.53    0.02   \n",
       "3       1.36   11.33     0.04    2.96    0.001        7.23      0.03    1.66   \n",
       "4       0.92   24.33     0.03    0.20    0.006        2.67      0.69    0.57   \n",
       "5       0.94   14.47     0.03    2.88    0.003        0.80      0.43    1.38   \n",
       "6       2.36     5.6     0.01    1.35    0.004        1.28      0.62    1.88   \n",
       "7       3.93   19.87     0.04    0.66    0.001        6.22      0.10    1.86   \n",
       "8       0.60   24.58     0.01    0.71    0.005        3.14      0.77    1.45   \n",
       "9       0.22   16.76     0.02    1.37    0.007        6.40      0.49    0.82   \n",
       "\n",
       "   flouride  bacteria  ...   lead  nitrates  nitrites  mercury  perchlorate  \\\n",
       "0      0.05      0.20  ...  0.054     16.08      1.13    0.007        37.75   \n",
       "1      0.90      0.65  ...  0.100      2.01      1.93    0.003        32.26   \n",
       "2      0.99      0.05  ...  0.078     14.16      1.11    0.006        50.28   \n",
       "3      1.08      0.71  ...  0.016      1.41      1.29    0.004         9.12   \n",
       "4      0.61      0.13  ...  0.117      6.74      1.11    0.003        16.90   \n",
       "5      0.11      0.67  ...  0.135      9.75      1.89    0.006        27.17   \n",
       "6      0.33      0.13  ...  0.021     18.60      1.78    0.007        45.34   \n",
       "7      0.86      0.16  ...  0.197     13.65      1.81    0.001        53.35   \n",
       "8      0.98      0.35  ...  0.167     14.66      1.84    0.004        23.43   \n",
       "9      1.24      0.83  ...  0.109      4.79      1.46    0.010        30.42   \n",
       "\n",
       "   radium  selenium  silver  uranium  is_safe  \n",
       "0    6.78      0.08    0.34     0.02        1  \n",
       "1    3.21      0.08    0.27     0.05        1  \n",
       "2    7.07      0.07    0.44     0.01        0  \n",
       "3    1.72      0.02    0.45     0.05        1  \n",
       "4    2.41      0.02    0.06     0.02        1  \n",
       "5    5.42      0.08    0.19     0.02        1  \n",
       "6    2.84      0.10    0.24     0.08        0  \n",
       "7    7.24      0.08    0.08     0.07        0  \n",
       "8    4.99      0.08    0.25     0.08        1  \n",
       "9    0.08      0.03    0.31     0.01        1  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  \\\n",
      "0          1.65    9.08     0.04    2.85    0.007        0.35      0.83   \n",
      "1          2.32   21.16     0.01    3.31    0.002        5.28      0.68   \n",
      "2          1.01   14.02     0.04    0.58    0.008        4.24      0.53   \n",
      "3          1.36   11.33     0.04    2.96    0.001        7.23      0.03   \n",
      "4          0.92   24.33     0.03    0.20    0.006        2.67      0.69   \n",
      "...         ...     ...      ...     ...      ...         ...       ...   \n",
      "7994       0.05    7.78     0.00    1.95    0.040        0.10      0.03   \n",
      "7995       0.05   24.22     0.02    0.59    0.010        0.45      0.02   \n",
      "7996       0.09    6.85     0.00    0.61    0.030        0.05      0.05   \n",
      "7997       0.01      10     0.01    2.00    0.000        2.00      0.00   \n",
      "7998       0.04    6.85     0.01    0.70    0.030        0.05      0.01   \n",
      "\n",
      "      copper  flouride  bacteria  ...   lead  nitrates  nitrites  mercury  \\\n",
      "0       0.17      0.05      0.20  ...  0.054     16.08      1.13    0.007   \n",
      "1       0.66      0.90      0.65  ...  0.100      2.01      1.93    0.003   \n",
      "2       0.02      0.99      0.05  ...  0.078     14.16      1.11    0.006   \n",
      "3       1.66      1.08      0.71  ...  0.016      1.41      1.29    0.004   \n",
      "4       0.57      0.61      0.13  ...  0.117      6.74      1.11    0.003   \n",
      "...      ...       ...       ...  ...    ...       ...       ...      ...   \n",
      "7994    0.03      1.37      0.00  ...  0.197     14.29      1.00    0.005   \n",
      "7995    0.02      1.48      0.00  ...  0.031     10.27      1.00    0.001   \n",
      "7996    0.02      0.91      0.00  ...  0.182     15.92      1.00    0.000   \n",
      "7997    0.09      0.00      0.00  ...  0.000      0.00      0.00    0.000   \n",
      "7998    0.03      1.00      0.00  ...  0.182     15.92      1.00    0.000   \n",
      "\n",
      "      perchlorate  radium  selenium  silver  uranium  is_safe  \n",
      "0           37.75    6.78      0.08    0.34     0.02        1  \n",
      "1           32.26    3.21      0.08    0.27     0.05        1  \n",
      "2           50.28    7.07      0.07    0.44     0.01        0  \n",
      "3            9.12    1.72      0.02    0.45     0.05        1  \n",
      "4           16.90    2.41      0.02    0.06     0.02        1  \n",
      "...           ...     ...       ...     ...      ...      ...  \n",
      "7994         3.57    2.13      0.09    0.06     0.03        1  \n",
      "7995         1.48    1.11      0.09    0.10     0.08        1  \n",
      "7996         1.35    4.84      0.00    0.04     0.05        1  \n",
      "7997         0.00    0.00      0.00    0.00     0.00        1  \n",
      "7998         1.35    4.84      0.00    0.04     0.05        1  \n",
      "\n",
      "[7999 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df_columna = df['is_safe'].apply(lambda x: isinstance(x, str))\n",
    "datos_string = df[df_columna]\n",
    "print(datos_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>0.03</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>0.06</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>0.01</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.009</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  \\\n",
       "7551       0.03   #NUM!     0.08    0.79     0.07        0.08      0.05   \n",
       "7568       0.06   #NUM!     0.07    1.72     0.08        0.32      0.01   \n",
       "7890       0.01   #NUM!     0.08    0.49     0.00        0.07      0.09   \n",
       "\n",
       "      copper  flouride  bacteria  ...   lead  nitrates  nitrites  mercury  \\\n",
       "7551    0.58      0.34      0.00  ...  0.183      4.37      1.43    0.007   \n",
       "7568    1.11      0.61      0.00  ...  0.178     12.10      2.03    0.008   \n",
       "7890    0.06      0.72      0.57  ...  0.088      9.57      1.45    0.009   \n",
       "\n",
       "      perchlorate  radium  selenium  silver  uranium  is_safe  \n",
       "7551         0.62    2.54      0.07    0.05     0.05    #NUM!  \n",
       "7568         1.37    2.05      0.06    0.10     0.07    #NUM!  \n",
       "7890         7.67    7.70      0.03    0.05     0.02    #NUM!  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df['is_safe'] == '#NUM!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>0.03</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>0.06</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>0.01</td>\n",
       "      <td>#NUM!</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.009</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>#NUM!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  \\\n",
       "7551       0.03   #NUM!     0.08    0.79     0.07        0.08      0.05   \n",
       "7568       0.06   #NUM!     0.07    1.72     0.08        0.32      0.01   \n",
       "7890       0.01   #NUM!     0.08    0.49     0.00        0.07      0.09   \n",
       "\n",
       "      copper  flouride  bacteria  ...   lead  nitrates  nitrites  mercury  \\\n",
       "7551    0.58      0.34      0.00  ...  0.183      4.37      1.43    0.007   \n",
       "7568    1.11      0.61      0.00  ...  0.178     12.10      2.03    0.008   \n",
       "7890    0.06      0.72      0.57  ...  0.088      9.57      1.45    0.009   \n",
       "\n",
       "      perchlorate  radium  selenium  silver  uranium  is_safe  \n",
       "7551         0.62    2.54      0.07    0.05     0.05    #NUM!  \n",
       "7568         1.37    2.05      0.06    0.10     0.07    #NUM!  \n",
       "7890         7.67    7.70      0.03    0.05     0.02    #NUM!  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df['ammonia'] == '#NUM!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[df_copy['is_safe'] != '#NUM!'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7996 entries, 0 to 7998\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   aluminium    7996 non-null   float64\n",
      " 1   ammonia      7996 non-null   object \n",
      " 2   arsenic      7996 non-null   float64\n",
      " 3   barium       7996 non-null   float64\n",
      " 4   cadmium      7996 non-null   float64\n",
      " 5   chloramine   7996 non-null   float64\n",
      " 6   chromium     7996 non-null   float64\n",
      " 7   copper       7996 non-null   float64\n",
      " 8   flouride     7996 non-null   float64\n",
      " 9   bacteria     7996 non-null   float64\n",
      " 10  viruses      7996 non-null   float64\n",
      " 11  lead         7996 non-null   float64\n",
      " 12  nitrates     7996 non-null   float64\n",
      " 13  nitrites     7996 non-null   float64\n",
      " 14  mercury      7996 non-null   float64\n",
      " 15  perchlorate  7996 non-null   float64\n",
      " 16  radium       7996 non-null   float64\n",
      " 17  selenium     7996 non-null   float64\n",
      " 18  silver       7996 non-null   float64\n",
      " 19  uranium      7996 non-null   float64\n",
      " 20  is_safe      7996 non-null   object \n",
      "dtypes: float64(19), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.65</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.007</td>\n",
       "      <td>37.75</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.32</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.26</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>50.28</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.36</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>24.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.94</td>\n",
       "      <td>14.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.006</td>\n",
       "      <td>27.17</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.36</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.007</td>\n",
       "      <td>45.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.93</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.001</td>\n",
       "      <td>53.35</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.60</td>\n",
       "      <td>24.58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167</td>\n",
       "      <td>14.66</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.004</td>\n",
       "      <td>23.43</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22</td>\n",
       "      <td>16.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.007</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aluminium ammonia  arsenic  barium  cadmium  chloramine  chromium  copper  \\\n",
       "0       1.65    9.08     0.04    2.85    0.007        0.35      0.83    0.17   \n",
       "1       2.32   21.16     0.01    3.31    0.002        5.28      0.68    0.66   \n",
       "2       1.01   14.02     0.04    0.58    0.008        4.24      0.53    0.02   \n",
       "3       1.36   11.33     0.04    2.96    0.001        7.23      0.03    1.66   \n",
       "4       0.92   24.33     0.03    0.20    0.006        2.67      0.69    0.57   \n",
       "5       0.94   14.47     0.03    2.88    0.003        0.80      0.43    1.38   \n",
       "6       2.36     5.6     0.01    1.35    0.004        1.28      0.62    1.88   \n",
       "7       3.93   19.87     0.04    0.66    0.001        6.22      0.10    1.86   \n",
       "8       0.60   24.58     0.01    0.71    0.005        3.14      0.77    1.45   \n",
       "9       0.22   16.76     0.02    1.37    0.007        6.40      0.49    0.82   \n",
       "\n",
       "   flouride  bacteria  ...   lead  nitrates  nitrites  mercury  perchlorate  \\\n",
       "0      0.05      0.20  ...  0.054     16.08      1.13    0.007        37.75   \n",
       "1      0.90      0.65  ...  0.100      2.01      1.93    0.003        32.26   \n",
       "2      0.99      0.05  ...  0.078     14.16      1.11    0.006        50.28   \n",
       "3      1.08      0.71  ...  0.016      1.41      1.29    0.004         9.12   \n",
       "4      0.61      0.13  ...  0.117      6.74      1.11    0.003        16.90   \n",
       "5      0.11      0.67  ...  0.135      9.75      1.89    0.006        27.17   \n",
       "6      0.33      0.13  ...  0.021     18.60      1.78    0.007        45.34   \n",
       "7      0.86      0.16  ...  0.197     13.65      1.81    0.001        53.35   \n",
       "8      0.98      0.35  ...  0.167     14.66      1.84    0.004        23.43   \n",
       "9      1.24      0.83  ...  0.109      4.79      1.46    0.010        30.42   \n",
       "\n",
       "   radium  selenium  silver  uranium  is_safe  \n",
       "0    6.78      0.08    0.34     0.02        1  \n",
       "1    3.21      0.08    0.27     0.05        1  \n",
       "2    7.07      0.07    0.44     0.01        0  \n",
       "3    1.72      0.02    0.45     0.05        1  \n",
       "4    2.41      0.02    0.06     0.02        1  \n",
       "5    5.42      0.08    0.19     0.02        1  \n",
       "6    2.84      0.10    0.24     0.08        0  \n",
       "7    7.24      0.08    0.08     0.07        0  \n",
       "8    4.99      0.08    0.25     0.08        1  \n",
       "9    0.08      0.03    0.31     0.01        1  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We normalize the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = MinMaxScaler()\n",
    "df_norm = pd.DataFrame(l.fit_transform(df_copy), columns=df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aluminium      1.0\n",
       "ammonia        1.0\n",
       "arsenic        1.0\n",
       "barium         1.0\n",
       "cadmium        1.0\n",
       "chloramine     1.0\n",
       "chromium       1.0\n",
       "copper         1.0\n",
       "flouride       1.0\n",
       "bacteria       1.0\n",
       "viruses        1.0\n",
       "lead           1.0\n",
       "nitrates       1.0\n",
       "nitrites       1.0\n",
       "mercury        1.0\n",
       "perchlorate    1.0\n",
       "radium         1.0\n",
       "selenium       1.0\n",
       "silver         1.0\n",
       "uranium        1.0\n",
       "is_safe        1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7996 entries, 0 to 7995\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   aluminium    7996 non-null   float64\n",
      " 1   ammonia      7996 non-null   float64\n",
      " 2   arsenic      7996 non-null   float64\n",
      " 3   barium       7996 non-null   float64\n",
      " 4   cadmium      7996 non-null   float64\n",
      " 5   chloramine   7996 non-null   float64\n",
      " 6   chromium     7996 non-null   float64\n",
      " 7   copper       7996 non-null   float64\n",
      " 8   flouride     7996 non-null   float64\n",
      " 9   bacteria     7996 non-null   float64\n",
      " 10  viruses      7996 non-null   float64\n",
      " 11  lead         7996 non-null   float64\n",
      " 12  nitrates     7996 non-null   float64\n",
      " 13  nitrites     7996 non-null   float64\n",
      " 14  mercury      7996 non-null   float64\n",
      " 15  perchlorate  7996 non-null   float64\n",
      " 16  radium       7996 non-null   float64\n",
      " 17  selenium     7996 non-null   float64\n",
      " 18  silver       7996 non-null   float64\n",
      " 19  uranium      7996 non-null   float64\n",
      " 20  is_safe      7996 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_norm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the database into train, validation, and tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = remove_labels(train_set, \"is_safe\")\n",
    "x_val, y_val = remove_labels(val_set, \"is_safe\")\n",
    "x_test, y_test = remove_labels(test_set, \"is_safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5502    0.0\n",
       "3915    0.0\n",
       "5331    0.0\n",
       "3404    0.0\n",
       "4222    0.0\n",
       "       ... \n",
       "5226    0.0\n",
       "5390    0.0\n",
       "860     1.0\n",
       "7603    0.0\n",
       "7270    0.0\n",
       "Name: is_safe, Length: 4797, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a tensorflow Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input((x_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,849</span> (26.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,849\u001b[0m (26.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,849</span> (26.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,849\u001b[0m (26.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8880 - loss: 0.3185 - val_accuracy: 0.8837 - val_loss: 0.2803\n",
      "Epoch 2/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9105 - loss: 0.2357 - val_accuracy: 0.8924 - val_loss: 0.2606\n",
      "Epoch 3/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9242 - loss: 0.1983 - val_accuracy: 0.9018 - val_loss: 0.2387\n",
      "Epoch 4/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9280 - loss: 0.1767 - val_accuracy: 0.9243 - val_loss: 0.1959\n",
      "Epoch 5/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9325 - loss: 0.1607 - val_accuracy: 0.9281 - val_loss: 0.1763\n",
      "Epoch 6/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9399 - loss: 0.1475 - val_accuracy: 0.9406 - val_loss: 0.1671\n",
      "Epoch 7/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9442 - loss: 0.1370 - val_accuracy: 0.9387 - val_loss: 0.1620\n",
      "Epoch 8/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9469 - loss: 0.1258 - val_accuracy: 0.9306 - val_loss: 0.1768\n",
      "Epoch 9/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9519 - loss: 0.1214 - val_accuracy: 0.9412 - val_loss: 0.1637\n",
      "Epoch 10/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9560 - loss: 0.1066 - val_accuracy: 0.9243 - val_loss: 0.1785\n",
      "Epoch 11/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9539 - loss: 0.1108 - val_accuracy: 0.9387 - val_loss: 0.1393\n",
      "Epoch 12/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9529 - loss: 0.1062 - val_accuracy: 0.9425 - val_loss: 0.1489\n",
      "Epoch 13/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9597 - loss: 0.0974 - val_accuracy: 0.9406 - val_loss: 0.1698\n",
      "Epoch 14/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9614 - loss: 0.0898 - val_accuracy: 0.9275 - val_loss: 0.1788\n",
      "Epoch 15/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9608 - loss: 0.0822 - val_accuracy: 0.9518 - val_loss: 0.1371\n",
      "Epoch 16/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9638 - loss: 0.0825 - val_accuracy: 0.9437 - val_loss: 0.1562\n",
      "Epoch 17/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9689 - loss: 0.0770 - val_accuracy: 0.9518 - val_loss: 0.1387\n",
      "Epoch 18/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9693 - loss: 0.0830 - val_accuracy: 0.9456 - val_loss: 0.1487\n",
      "Epoch 19/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9700 - loss: 0.0758 - val_accuracy: 0.9450 - val_loss: 0.1470\n",
      "Epoch 20/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9667 - loss: 0.0791 - val_accuracy: 0.9487 - val_loss: 0.1438\n",
      "Epoch 21/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9729 - loss: 0.0713 - val_accuracy: 0.9437 - val_loss: 0.1703\n",
      "Epoch 22/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9684 - loss: 0.0760 - val_accuracy: 0.9443 - val_loss: 0.1584\n",
      "Epoch 23/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9677 - loss: 0.0723 - val_accuracy: 0.9468 - val_loss: 0.1422\n",
      "Epoch 24/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9834 - loss: 0.0544 - val_accuracy: 0.9425 - val_loss: 0.1435\n",
      "Epoch 25/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9724 - loss: 0.0642 - val_accuracy: 0.9431 - val_loss: 0.1780\n",
      "Epoch 26/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9743 - loss: 0.0572 - val_accuracy: 0.9493 - val_loss: 0.1599\n",
      "Epoch 27/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9750 - loss: 0.0604 - val_accuracy: 0.9443 - val_loss: 0.1615\n",
      "Epoch 28/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9785 - loss: 0.0553 - val_accuracy: 0.9512 - val_loss: 0.1403\n",
      "Epoch 29/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9795 - loss: 0.0569 - val_accuracy: 0.9506 - val_loss: 0.1483\n",
      "Epoch 30/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9782 - loss: 0.0519 - val_accuracy: 0.9493 - val_loss: 0.1414\n",
      "Epoch 31/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9827 - loss: 0.0460 - val_accuracy: 0.9475 - val_loss: 0.1623\n",
      "Epoch 32/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9819 - loss: 0.0459 - val_accuracy: 0.9406 - val_loss: 0.1826\n",
      "Epoch 33/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9828 - loss: 0.0411 - val_accuracy: 0.9500 - val_loss: 0.1609\n",
      "Epoch 34/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9883 - loss: 0.0358 - val_accuracy: 0.9381 - val_loss: 0.1822\n",
      "Epoch 35/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9825 - loss: 0.0434 - val_accuracy: 0.9475 - val_loss: 0.1642\n",
      "Epoch 36/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9842 - loss: 0.0403 - val_accuracy: 0.9475 - val_loss: 0.1723\n",
      "Epoch 37/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9897 - loss: 0.0323 - val_accuracy: 0.9468 - val_loss: 0.1732\n",
      "Epoch 38/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9866 - loss: 0.0343 - val_accuracy: 0.9443 - val_loss: 0.1834\n",
      "Epoch 39/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9870 - loss: 0.0380 - val_accuracy: 0.9431 - val_loss: 0.1909\n",
      "Epoch 40/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9877 - loss: 0.0393 - val_accuracy: 0.9481 - val_loss: 0.1988\n",
      "Epoch 41/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9895 - loss: 0.0302 - val_accuracy: 0.9500 - val_loss: 0.1932\n",
      "Epoch 42/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9917 - loss: 0.0259 - val_accuracy: 0.9475 - val_loss: 0.2001\n",
      "Epoch 43/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9894 - loss: 0.0331 - val_accuracy: 0.9481 - val_loss: 0.1835\n",
      "Epoch 44/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9910 - loss: 0.0300 - val_accuracy: 0.9487 - val_loss: 0.1992\n",
      "Epoch 45/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9883 - loss: 0.0324 - val_accuracy: 0.9487 - val_loss: 0.2057\n",
      "Epoch 46/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9944 - loss: 0.0228 - val_accuracy: 0.9418 - val_loss: 0.2244\n",
      "Epoch 47/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9915 - loss: 0.0240 - val_accuracy: 0.9456 - val_loss: 0.1937\n",
      "Epoch 48/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9903 - loss: 0.0285 - val_accuracy: 0.9400 - val_loss: 0.2282\n",
      "Epoch 49/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9928 - loss: 0.0234 - val_accuracy: 0.9468 - val_loss: 0.2090\n",
      "Epoch 50/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9879 - loss: 0.0313 - val_accuracy: 0.9387 - val_loss: 0.2123\n",
      "Epoch 51/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9906 - loss: 0.0242 - val_accuracy: 0.9500 - val_loss: 0.2034\n",
      "Epoch 52/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9959 - loss: 0.0161 - val_accuracy: 0.9493 - val_loss: 0.1939\n",
      "Epoch 53/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9953 - loss: 0.0124 - val_accuracy: 0.9493 - val_loss: 0.2027\n",
      "Epoch 54/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9933 - loss: 0.0216 - val_accuracy: 0.9325 - val_loss: 0.2599\n",
      "Epoch 55/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9886 - loss: 0.0311 - val_accuracy: 0.9462 - val_loss: 0.2614\n",
      "Epoch 56/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9942 - loss: 0.0152 - val_accuracy: 0.9462 - val_loss: 0.2228\n",
      "Epoch 57/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.9381 - val_loss: 0.2696\n",
      "Epoch 58/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9914 - loss: 0.0240 - val_accuracy: 0.9462 - val_loss: 0.2202\n",
      "Epoch 59/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9969 - loss: 0.0133 - val_accuracy: 0.9400 - val_loss: 0.2683\n",
      "Epoch 60/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9925 - loss: 0.0236 - val_accuracy: 0.9275 - val_loss: 0.2947\n",
      "Epoch 61/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9889 - loss: 0.0293 - val_accuracy: 0.9425 - val_loss: 0.2362\n",
      "Epoch 62/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9914 - loss: 0.0203 - val_accuracy: 0.9462 - val_loss: 0.2612\n",
      "Epoch 63/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9951 - loss: 0.0126 - val_accuracy: 0.9437 - val_loss: 0.2295\n",
      "Epoch 64/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9954 - loss: 0.0160 - val_accuracy: 0.9525 - val_loss: 0.2197\n",
      "Epoch 65/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9940 - loss: 0.0206 - val_accuracy: 0.9481 - val_loss: 0.2269\n",
      "Epoch 66/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9946 - loss: 0.0142 - val_accuracy: 0.9493 - val_loss: 0.2659\n",
      "Epoch 67/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9922 - loss: 0.0196 - val_accuracy: 0.9481 - val_loss: 0.2191\n",
      "Epoch 68/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9962 - loss: 0.0125 - val_accuracy: 0.9493 - val_loss: 0.2517\n",
      "Epoch 69/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9959 - loss: 0.0160 - val_accuracy: 0.9475 - val_loss: 0.2313\n",
      "Epoch 70/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9953 - loss: 0.0145 - val_accuracy: 0.9481 - val_loss: 0.2428\n",
      "Epoch 71/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9940 - loss: 0.0183 - val_accuracy: 0.9456 - val_loss: 0.2601\n",
      "Epoch 72/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9921 - loss: 0.0179 - val_accuracy: 0.9518 - val_loss: 0.2860\n",
      "Epoch 73/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9947 - loss: 0.0170 - val_accuracy: 0.9493 - val_loss: 0.2465\n",
      "Epoch 74/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9988 - loss: 0.0082 - val_accuracy: 0.9487 - val_loss: 0.2729\n",
      "Epoch 75/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9368 - val_loss: 0.2648\n",
      "Epoch 76/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9908 - loss: 0.0234 - val_accuracy: 0.9475 - val_loss: 0.2342\n",
      "Epoch 77/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9985 - loss: 0.0082 - val_accuracy: 0.9475 - val_loss: 0.3264\n",
      "Epoch 78/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.9456 - val_loss: 0.2694\n",
      "Epoch 79/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.9487 - val_loss: 0.2708\n",
      "Epoch 80/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9987 - loss: 0.0061 - val_accuracy: 0.9450 - val_loss: 0.2951\n",
      "Epoch 81/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.9387 - val_loss: 0.2789\n",
      "Epoch 82/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9940 - loss: 0.0194 - val_accuracy: 0.9493 - val_loss: 0.2843\n",
      "Epoch 83/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9450 - val_loss: 0.3370\n",
      "Epoch 84/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9961 - loss: 0.0109 - val_accuracy: 0.9443 - val_loss: 0.2957\n",
      "Epoch 85/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 0.9468 - val_loss: 0.2673\n",
      "Epoch 86/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.9468 - val_loss: 0.2825\n",
      "Epoch 87/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9949 - loss: 0.0148 - val_accuracy: 0.9450 - val_loss: 0.2667\n",
      "Epoch 88/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.9481 - val_loss: 0.2987\n",
      "Epoch 89/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9999 - loss: 0.0027 - val_accuracy: 0.9462 - val_loss: 0.3328\n",
      "Epoch 90/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9931 - loss: 0.0196 - val_accuracy: 0.9468 - val_loss: 0.3081\n",
      "Epoch 91/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9971 - loss: 0.0104 - val_accuracy: 0.9468 - val_loss: 0.3280\n",
      "Epoch 92/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9487 - val_loss: 0.2813\n",
      "Epoch 93/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 0.9475 - val_loss: 0.3189\n",
      "Epoch 94/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.9493 - val_loss: 0.3173\n",
      "Epoch 95/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9956 - loss: 0.0126 - val_accuracy: 0.9406 - val_loss: 0.3395\n",
      "Epoch 96/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9918 - loss: 0.0206 - val_accuracy: 0.9468 - val_loss: 0.3295\n",
      "Epoch 97/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.9990 - loss: 0.0057 - val_accuracy: 0.9450 - val_loss: 0.3458\n",
      "Epoch 98/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 0.9487 - val_loss: 0.2950\n",
      "Epoch 99/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.9487 - val_loss: 0.3351\n",
      "Epoch 100/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.9487 - val_loss: 0.2988\n",
      "Epoch 101/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9406 - val_loss: 0.3941\n",
      "Epoch 102/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9903 - loss: 0.0378 - val_accuracy: 0.9425 - val_loss: 0.2966\n",
      "Epoch 103/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9992 - loss: 0.0058 - val_accuracy: 0.9475 - val_loss: 0.2857\n",
      "Epoch 104/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9978 - loss: 0.0079 - val_accuracy: 0.9512 - val_loss: 0.2888\n",
      "Epoch 105/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.9506 - val_loss: 0.3242\n",
      "Epoch 106/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9950 - loss: 0.0125 - val_accuracy: 0.9325 - val_loss: 0.3540\n",
      "Epoch 107/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9931 - loss: 0.0197 - val_accuracy: 0.9468 - val_loss: 0.2921\n",
      "Epoch 108/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9985 - loss: 0.0079 - val_accuracy: 0.9406 - val_loss: 0.3187\n",
      "Epoch 109/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9977 - loss: 0.0104 - val_accuracy: 0.9325 - val_loss: 0.3436\n",
      "Epoch 110/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9512 - val_loss: 0.3025\n",
      "Epoch 111/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9962 - loss: 0.0092 - val_accuracy: 0.9393 - val_loss: 0.3540\n",
      "Epoch 112/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9958 - loss: 0.0108 - val_accuracy: 0.9443 - val_loss: 0.3602\n",
      "Epoch 113/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.9487 - val_loss: 0.3290\n",
      "Epoch 114/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9953 - loss: 0.0121 - val_accuracy: 0.9487 - val_loss: 0.3639\n",
      "Epoch 115/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9966 - loss: 0.0136 - val_accuracy: 0.9500 - val_loss: 0.3202\n",
      "Epoch 116/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9456 - val_loss: 0.3119\n",
      "Epoch 117/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9525 - val_loss: 0.3309\n",
      "Epoch 118/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9500 - val_loss: 0.3273\n",
      "Epoch 119/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9362 - val_loss: 0.4337\n",
      "Epoch 120/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9933 - loss: 0.0203 - val_accuracy: 0.9512 - val_loss: 0.3088\n",
      "Epoch 121/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.9493 - val_loss: 0.3348\n",
      "Epoch 122/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9506 - val_loss: 0.3147\n",
      "Epoch 123/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9456 - val_loss: 0.3231\n",
      "Epoch 124/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9931 - loss: 0.0204 - val_accuracy: 0.9468 - val_loss: 0.3406\n",
      "Epoch 125/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9493 - val_loss: 0.3256\n",
      "Epoch 126/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9506 - val_loss: 0.3463\n",
      "Epoch 127/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9443 - val_loss: 0.3642\n",
      "Epoch 128/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9487 - val_loss: 0.3289\n",
      "Epoch 129/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9387 - val_loss: 0.3580\n",
      "Epoch 130/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9892 - loss: 0.0293 - val_accuracy: 0.9337 - val_loss: 0.3286\n",
      "Epoch 131/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.9475 - val_loss: 0.3211\n",
      "Epoch 132/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9512 - val_loss: 0.3201\n",
      "Epoch 133/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9500 - val_loss: 0.3499\n",
      "Epoch 134/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9500 - val_loss: 0.3374\n",
      "Epoch 135/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9300 - val_loss: 0.3516\n",
      "Epoch 136/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9918 - loss: 0.0180 - val_accuracy: 0.9506 - val_loss: 0.3541\n",
      "Epoch 137/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9400 - val_loss: 0.5005\n",
      "Epoch 138/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9989 - loss: 0.0056 - val_accuracy: 0.9450 - val_loss: 0.3590\n",
      "Epoch 139/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9981 - loss: 0.0026 - val_accuracy: 0.9500 - val_loss: 0.3786\n",
      "Epoch 140/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9929 - loss: 0.0154 - val_accuracy: 0.9325 - val_loss: 0.4058\n",
      "Epoch 141/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9950 - loss: 0.0136 - val_accuracy: 0.9518 - val_loss: 0.3216\n",
      "Epoch 142/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9481 - val_loss: 0.3459\n",
      "Epoch 143/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9512 - val_loss: 0.3254\n",
      "Epoch 144/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9475 - val_loss: 0.3376\n",
      "Epoch 145/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9437 - val_loss: 0.3877\n",
      "Epoch 146/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9962 - loss: 0.0099 - val_accuracy: 0.9487 - val_loss: 0.3761\n",
      "Epoch 147/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9949 - loss: 0.0177 - val_accuracy: 0.9468 - val_loss: 0.3349\n",
      "Epoch 148/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9468 - val_loss: 0.3603\n",
      "Epoch 149/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.9437 - val_loss: 0.3372\n",
      "Epoch 150/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9462 - val_loss: 0.3285\n",
      "Epoch 151/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9431 - val_loss: 0.3779\n",
      "Epoch 152/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 0.9487 - val_loss: 0.3409\n",
      "Epoch 153/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9431 - val_loss: 0.3716\n",
      "Epoch 154/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9518 - val_loss: 0.3746\n",
      "Epoch 155/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9481 - val_loss: 0.3600\n",
      "Epoch 156/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9325 - val_loss: 0.4068\n",
      "Epoch 157/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9456 - val_loss: 0.3809\n",
      "Epoch 158/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9487 - val_loss: 0.3893\n",
      "Epoch 159/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9500 - val_loss: 0.3826\n",
      "Epoch 160/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9481 - val_loss: 0.3841\n",
      "Epoch 161/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9381 - val_loss: 0.4047\n",
      "Epoch 162/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 0.9456 - val_loss: 0.3867\n",
      "Epoch 163/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9981 - loss: 0.0036 - val_accuracy: 0.9481 - val_loss: 0.4344\n",
      "Epoch 164/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9431 - val_loss: 0.4057\n",
      "Epoch 165/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9450 - val_loss: 0.4260\n",
      "Epoch 166/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9481 - val_loss: 0.4012\n",
      "Epoch 167/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9946 - loss: 0.0128 - val_accuracy: 0.9462 - val_loss: 0.3659\n",
      "Epoch 168/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9487 - val_loss: 0.3818\n",
      "Epoch 169/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.9468 - val_loss: 0.3699\n",
      "Epoch 170/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9487 - val_loss: 0.3396\n",
      "Epoch 171/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9487 - val_loss: 0.3369\n",
      "Epoch 172/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9992 - loss: 0.0016 - val_accuracy: 0.9493 - val_loss: 0.3675\n",
      "Epoch 173/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9493 - val_loss: 0.3386\n",
      "Epoch 174/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9475 - val_loss: 0.3570\n",
      "Epoch 175/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9362 - val_loss: 0.4095\n",
      "Epoch 176/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9888 - loss: 0.0287 - val_accuracy: 0.9500 - val_loss: 0.3783\n",
      "Epoch 177/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9475 - val_loss: 0.4144\n",
      "Epoch 178/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9443 - val_loss: 0.4444\n",
      "Epoch 179/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9362 - val_loss: 0.4226\n",
      "Epoch 180/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9487 - val_loss: 0.3637\n",
      "Epoch 181/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.9462 - val_loss: 0.3763\n",
      "Epoch 182/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9462 - val_loss: 0.3537\n",
      "Epoch 183/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9512 - val_loss: 0.3777\n",
      "Epoch 184/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9500 - val_loss: 0.3697\n",
      "Epoch 185/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.9468 - val_loss: 0.3575\n",
      "Epoch 186/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.9481 - val_loss: 0.3970\n",
      "Epoch 187/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9506 - val_loss: 0.3632\n",
      "Epoch 188/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9468 - val_loss: 0.4923\n",
      "Epoch 189/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9468 - val_loss: 0.4107\n",
      "Epoch 190/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9948 - loss: 0.0156 - val_accuracy: 0.9493 - val_loss: 0.4378\n",
      "Epoch 191/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.9506 - val_loss: 0.3676\n",
      "Epoch 192/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9998 - loss: 7.7495e-04 - val_accuracy: 0.9518 - val_loss: 0.3607\n",
      "Epoch 193/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9493 - val_loss: 0.4036\n",
      "Epoch 194/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9456 - val_loss: 0.4131\n",
      "Epoch 195/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9481 - val_loss: 0.3548\n",
      "Epoch 196/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9487 - val_loss: 0.3702\n",
      "Epoch 197/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.9983 - loss: 0.0034 - val_accuracy: 0.9475 - val_loss: 0.3789\n",
      "Epoch 198/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.9375 - val_loss: 0.5246\n",
      "Epoch 199/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0189 - val_accuracy: 0.9487 - val_loss: 0.3831\n",
      "Epoch 200/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9978 - loss: 0.0053 - val_accuracy: 0.9418 - val_loss: 0.3547\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=200, batch_size=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "y_pred = np.rint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1341   76]\n",
      " [  41  142]]\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1092b70a630>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGwCAYAAAAXNjfEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9RUlEQVR4nO3dfVhUdf7/8dcotxKgoIBjqFBmlmSKrWHbautdmndfd9f62pq7mWWWRmiauSVbK65+WyW11FwLVzNrKyv7mSuWWaamoLRprq1FiimhG4IitzPn94c52wRngpnBAXw+rutcV3PO53N4DzvrvHl/bo7FMAxDAAAAddTM1wEAAIDGiSQCAAC4hSQCAAC4hSQCAAC4hSQCAAC4hSQCAAC4hSQCAAC4xc/XAVxsdrtdx48fV2hoqCwWi6/DAQDUkWEYOnPmjKxWq5o1q7+/hcvKylRRUeHxfQICAhQUFOSFiBqeSy6JOH78uGJjY30dBgDAQ3l5ebr88svr5d5lZWWK63CZ8gtsHt8rJiZGubm5TTKRuOSSiNDQUEnSkb0dFXYZozlomn51XU9fhwDUmyqjUh+Wr3f8e14fKioqlF9g05HsjgoLdf+7oviMXR0Sv1ZFRQVJRFNwYQgj7LJmHn0wgIbMzxLg6xCAencxhqQvC7XoslD3f45dTXvY/JJLIgAAqC2bYZfNgydM2Qy794JpgEgiAAAwYZchu9zPIjzp2xhQzwcAAG6hEgEAgAm77PJkQMKz3g0fSQQAACZshiGb4f6QhCd9GwOGMwAAgFuoRAAAYIKJla6RRAAAYMIuQzaSCFMMZwAAALdQiQAAwATDGa6RRAAAYILVGa4xnAEAANxCJQIAABP27w9P+jdlJBEAAJiwebg6w5O+jQFJBAAAJmyGPHyKp/diaYiYEwEAANxCJQIAABPMiXCNJAIAABN2WWSTxaP+TRnDGQAAwC1UIgAAMGE3zh+e9G/KSCIAADBh83A4w5O+jQHDGQAAwC1UIgAAMEElwjWSCAAATNgNi+yGB6szPOjbGDCcAQAA3EIlAgAAEwxnuEYSAQCACZuayeZB0d7mxVgaIpIIAABMGB7OiTCYEwEAAFAdlQgAAEwwJ8I1kggAAEzYjGayGR7MiWji214znAEAANxCJQIAABN2WWT34O9tu5p2KYIkAgAAE8yJcI3hDAAAGpAPP/xQw4YNk9VqlcVi0Ztvvum4VllZqRkzZighIUEhISGyWq266667dPz4cad7lJeXa/LkyWrdurVCQkI0fPhwHTt2zKlNYWGhxo4dq/DwcIWHh2vs2LE6ffp0nWIliQAAwMSFiZWeHHVVUlKibt26acmSJdWunTt3Tnv37tXjjz+uvXv36o033tAXX3yh4cOHO7VLTk7W+vXrtW7dOm3fvl1nz57V0KFDZbP9d/urMWPGKCcnR5s2bdKmTZuUk5OjsWPH1ilWhjMAADBxfk6EBw/g+r5vcXGx0/nAwEAFBgbW2Gfw4MEaPHhwjdfCw8OVmZnpdG7x4sX62c9+pqNHj6p9+/YqKirSypUrtXr1avXv31+StGbNGsXGxmrLli0aNGiQDh48qE2bNmnXrl3q1auXJGnFihVKSkrSoUOH1Llz51q9PyoRAADUs9jYWMewQXh4uObOneu1excVFclisahly5aSpOzsbFVWVmrgwIGONlarVV27dtWOHTskSTt37lR4eLgjgZCkG2+8UeHh4Y42tUElAgAAE3YPn51xYXVGXl6ewsLCHOfNqhB1VVZWpkcffVRjxoxx3D8/P18BAQFq1aqVU9vo6Gjl5+c72kRFRVW7X1RUlKNNbZBEAABgwvPNps4nEWFhYU5JhDdUVlbqjjvukN1u13PPPfeT7Q3DkMXy36GZH/63WZufwnAGAAAm7Grm8VEfKisrNXr0aOXm5iozM9MpQYmJiVFFRYUKCwud+hQUFCg6OtrR5ttvv61235MnTzra1AZJBAAAjciFBOLf//63tmzZosjISKfriYmJ8vf3d5qAeeLECe3fv1+9e/eWJCUlJamoqEi7d+92tPnkk09UVFTkaFMbDGcAAGDCZlhk8+Bx3u70PXv2rA4fPux4nZubq5ycHEVERMhqterXv/619u7dq3feeUc2m80xhyEiIkIBAQEKDw/X+PHjNXXqVEVGRioiIkLTpk1TQkKCY7VGly5ddOutt2rChAlavny5JOnee+/V0KFDa70yQyKJAADAlM3DiZU2N7a9zsrK0i233OJ4nZKSIkkaN26cUlNT9fbbb0uSrr/+eqd+W7duVd++fSVJCxculJ+fn0aPHq3S0lL169dPGRkZat68uaP9Sy+9pClTpjhWcQwfPrzGvSlcIYkAAKAB6du3rwzDPPlwde2CoKAgLV68WIsXLzZtExERoTVr1rgV4wUkEQAAmLAbzWT3YHWGvRZf+I0ZSQQAACZ8MZzRmLA6AwAAuIVKBAAAJuxyb4XFD/s3ZSQRAACY8HTDqPrabKqhaNrvDgAA1BsqEQAAmPD82RlN+291kggAAEzYZZFdnsyJcL9vY0ASAQCACSoRrjXtdwcAAOoNlQgAAEx4vtlU0/5bnSQCAAATdsMiuyf7RHjQtzFo2ikSAACoN1QiAAAwYfdwOKOpbzZFEgEAgAnPn+LZtJOIpv3uAABAvaESAQCACZsssnmwYZQnfRsDkggAAEwwnOFa0353AACg3lCJAADAhE2eDUnYvBdKg0QSAQCACYYzXCOJAADABA/gcq1pvzsAAFBvqEQAAGDCkEV2D+ZEGCzxBADg0sRwhmtN+90BAIB6QyUCAAATPArcNZIIAABM2Dx8iqcnfRuDpv3uAABAvaESAQCACYYzXCOJAADAhF3NZPegaO9J38agab87AABQb6hEAABgwmZYZPNgSMKTvo0BSQQAACaYE+EaSQQAACYMD5/iabBjJQAAQHVUIgAAMGGTRTYPHqLlSd/GgCQCAAATdsOzeQ12w4vBNEAMZwAAALdQiUCtfLYrRH9/Lkr//qyFvvvWX7NX5qr34CLH9dVPx+iDt1rq5HF/+QcYujKhVL9/9ISu7nGu2r0MQ/rDb+OVtTWs2n3WPhOt3VvC9NWBYPkFGHrjX59dlPcH/JSMD/cp+vKKauc3rI7Sc7PjJEmxV5Tq7hlHldDrjCwWQ0f/Hay0yZ108njgxQ4XXmL3cGKlJ30bA5II1ErZuWaKv7ZUA+/4Tk/dE1fterv4Mj0w55jadqhQeVkzrX++jWb+7xV6ccfnahlpc2q7fkUbWUyqg1UVFv1i2Gl16Vmif7wcWR9vBXDLQyO7qlmz/9amO3Qu1dzV/9JHG89/Ttu2L9PTr36uf7zaRmvSL1fJmeaKvbJUFeVN+0ukqbPLIrsH8xo86dsY+PzT/dxzzykuLk5BQUFKTEzURx995LL9tm3blJiYqKCgIMXHx2vZsmUXKdJL2w2/PKPfzcjXz4cU1Xj9l6NOq8cvzqpthwp17Fyme1O/0bkzzZX7ebBTuy8PBOn15W2UsuBojfe565F8jbr3pOKuLvP6ewA8UfSdvwpPBTiOXr88reNfB+qzT0IlSeOm5mnPB+F6YV57ffl5iPLzgrRnaysV/cffx5ED9cenScQrr7yi5ORkzZo1S/v27dPNN9+swYMH6+jRmr9gcnNzNWTIEN18883at2+fHnvsMU2ZMkWvv/76RY4crlRWWLRxTaRCwmyKv6bUcb7snEV/ntRRD8w5poioKh9GCHjGz9+uW0ac0ubX2kiyyGIxdMMtp/VNbrD+lPEvvbw7Wwvf2K+kAd/5OlR46MKOlZ4cTZlPk4gFCxZo/Pjxuueee9SlSxelp6crNjZWS5curbH9smXL1L59e6Wnp6tLly665557dPfdd+vpp5++yJGjJrsywzTiygQNi7tO61e00dx1hxX+g6GM5antdE3PEvW+tdiHUQKeSxpQqMvCqpT5WhtJUsvISrW4zK7RE48r68NwzRp3tXZsjtAflv5bCT/j896YXZgT4cnRlPns3VVUVCg7O1sDBw50Oj9w4EDt2LGjxj47d+6s1n7QoEHKyspSZWVljX3Ky8tVXFzsdKB+XH/TWT2XeUgL3/63evY9ozn3ddTpU+en3ez8R5hyPg7VxCe/8XGUgOcGjT6prG0t9V1BgCTJ8v2/pDu3tNKbL7TVVwdD9PdlVu1+v6WG3Fngw0iB+uWzJOLUqVOy2WyKjo52Oh8dHa38/Pwa++Tn59fYvqqqSqdOnaqxz9y5cxUeHu44YmNjvfMGUE1QC7vaxVWoS+I5pSzIU3M/adPLEZKknI9DdeLrAI26OkGDY7tpcGw3SdJTEzrqkV9d6cuwgTqJspbr+puKtOmVNo5zxYV+qqq06Oi/necA5X0ZrDZtyy92iPAiuyyO52e4dbgxsfLDDz/UsGHDZLVaZbFY9OabbzpdNwxDqampslqtCg4OVt++fXXgwAGnNuXl5Zo8ebJat26tkJAQDR8+XMeOHXNqU1hYqLFjxzq+H8eOHavTp0/XKVaf11ksP5qmbxhGtXM/1b6m8xfMnDlTRUVFjiMvL8/DiFFbhiFVfj8z/fYHv9Wy9w5paeZ/D0m6L/UbTV1Y8xwYoCEa8JuTKvqPv3ZvbeU4V1XZTF/8M0SXx5c6tW3XsUwFLO9s1IzvV2e4exhuJBElJSXq1q2blixZUuP1+fPna8GCBVqyZIn27NmjmJgYDRgwQGfOnHG0SU5O1vr167Vu3Tpt375dZ8+e1dChQ2Wz/XeIecyYMcrJydGmTZu0adMm5eTkaOzYsXWK1WdLPFu3bq3mzZtXqzoUFBRUqzZcEBMTU2N7Pz8/RUbWvBwwMDBQgYH8n9hTpSXNdDz3v7/H/LwAfbk/WKEtqxQWYdPaZ6KVNLBIEdGVKv7OT++saq1TJ/x187DTkqSIqKoaJ1NGtatUTPv/rr0vOOavM6f9VPCNv+w26cv95/+ys8aVKzjEXr9vEvgJFouhAb8+qS1vtJbd5vzl8PqKtnp00WHt312gT3eFqecvTqtXv0LNGHONj6KFN/jiKZ6DBw/W4MGDa7xmGIbS09M1a9YsjRo1SpK0atUqRUdHa+3atbrvvvtUVFSklStXavXq1erfv78kac2aNYqNjdWWLVs0aNAgHTx4UJs2bdKuXbvUq1cvSdKKFSuUlJSkQ4cOqXPnzrWK1WdJREBAgBITE5WZman/+Z//cZzPzMzUiBEjauyTlJSkDRs2OJ3bvHmzevbsKX9/llHVpy8+baHpv/7vsMPy1HaSpAGjv9OUP+fp2OFAPfX3jir+zk+hrWy6qts5/WX9v9Wxc92Wav7t6bbKfDXC8XrSwPMf5PmvHVa33me98E4A93W/qUjR7Sq0+e9tql3bsTlCSx7vqNH3H9fE2V/r2FfB+tOkTjqQFeqDSNHQ/Hg+nrt/4Obm5io/P99pfmBgYKD69OmjHTt26L777lN2drYqKyud2litVnXt2lU7duzQoEGDtHPnToWHhzsSCEm68cYbFR4erh07djT8JEKSUlJSNHbsWPXs2VNJSUl6/vnndfToUU2cOFHS+aGIb775Rn/7298kSRMnTtSSJUuUkpKiCRMmaOfOnVq5cqVefvllX76NS0K33mf1j+M5ptefWPl1ne9Z0/2mpR/VtHSGN9Aw7d3eUoPje5le3/z3KG3+e9RFjAj1zVs7Vv54Pt7s2bOVmppa5/tdqMbXND/wyJEjjjYBAQFq1apVtTYX+ufn5ysqqvpnNSoqynReYk18mkTcfvvt+s9//qMnn3xSJ06cUNeuXbVx40Z16NBBknTixAmnPSPi4uK0ceNGPfzww3r22WdltVq1aNEi/epXv/LVWwAANGHeGs7Iy8tTWFiY47ynw+x1nU9YU5ua2tfmPj/k822vJ02apEmTJtV4LSMjo9q5Pn36aO/evfUcFQAA3hMWFuaURLgrJiZG0vlKQtu2bR3nfzifMCYmRhUVFSosLHSqRhQUFKh3796ONt9++221+588edJ0XmJNfL46AwCAhsqTlRmePnejJnFxcYqJiVFmZqbjXEVFhbZt2+ZIEBITE+Xv7+/U5sSJE9q/f7+jTVJSkoqKirR7925Hm08++URFRUWONrXh80oEAAANlS9WZ5w9e1aHDx92vM7NzVVOTo4iIiLUvn17JScnKy0tTZ06dVKnTp2UlpamFi1aaMyYMZKk8PBwjR8/XlOnTlVkZKQiIiI0bdo0JSQkOFZrdOnSRbfeeqsmTJig5cuXS5LuvfdeDR06tNaTKiWSCAAAGpSsrCzdcsstjtcpKSmSpHHjxikjI0PTp09XaWmpJk2apMLCQvXq1UubN29WaOh/VwItXLhQfn5+Gj16tEpLS9WvXz9lZGSoefPmjjYvvfSSpkyZ4ljFMXz4cNO9KcxYjAu7NV0iiouLFR4ersIv4hUWymgOmqbB8Tf6OgSg3lQZFXq/7FUVFRV5ZZ5BTS58VwzeNEH+IQFu36eypELv3rqiXmP1JSoRAACY8MVwRmPCn+IAAMAtVCIAADBBJcI1kggAAEwYkkfLNJv6pEOSCAAATFCJcI05EQAAwC1UIgAAMEElwjWSCAAATJBEuMZwBgAAcAuVCAAATFCJcI0kAgAAE4ZhkeFBIuBJ38aA4QwAAOAWKhEAAJiwy+LRZlOe9G0MSCIAADDBnAjXGM4AAABuoRIBAIAJJla6RhIBAIAJhjNcI4kAAMAElQjXmBMBAADcQiUCAAAThofDGU29EkESAQCACUOSYXjWvyljOAMAALiFSgQAACbsssjCjpWmSCIAADDB6gzXGM4AAABuoRIBAIAJu2GRhc2mTJFEAABgwjA8XJ3RxJdnMJwBAADcQiUCAAATTKx0jSQCAAATJBGukUQAAGCCiZWuMScCAAC4hUoEAAAmWJ3hGkkEAAAmzicRnsyJ8GIwDRDDGQAAwC1UIgAAMMHqDNdIIgAAMGF8f3jSvyljOAMAALiFSgQAACYYznCNJAIAADOMZ7hEEgEAgBkPKxFq4pUI5kQAAAC3UIkAAMAEO1a6RhIBAIAJJla6xnAGAABwC5UIAADMGBbPJkdSiQAA4NJ0YU6EJ0ddVFVV6Q9/+IPi4uIUHBys+Ph4Pfnkk7Lb7T+IyVBqaqqsVquCg4PVt29fHThwwOk+5eXlmjx5slq3bq2QkBANHz5cx44d88avxAlJBAAADcS8efO0bNkyLVmyRAcPHtT8+fP1f//3f1q8eLGjzfz587VgwQItWbJEe/bsUUxMjAYMGKAzZ8442iQnJ2v9+vVat26dtm/frrNnz2ro0KGy2WxejZfhDAAAzFzkzaZ27typESNG6LbbbpMkdezYUS+//LKysrLO384wlJ6erlmzZmnUqFGSpFWrVik6Olpr167Vfffdp6KiIq1cuVKrV69W//79JUlr1qxRbGystmzZokGDBnnwhpxRiQAAwMSF1RmeHJJUXFzsdJSXl9f4837+85/rvffe0xdffCFJ+vTTT7V9+3YNGTJEkpSbm6v8/HwNHDjQ0ScwMFB9+vTRjh07JEnZ2dmqrKx0amO1WtW1a1dHG2+pVSVi0aJFtb7hlClT3A4GAICmKDY21un17NmzlZqaWq3djBkzVFRUpKuvvlrNmzeXzWbTnDlz9L//+7+SpPz8fElSdHS0U7/o6GgdOXLE0SYgIECtWrWq1uZCf2+pVRKxcOHCWt3MYrGQRAAAmhYvbBiVl5ensLAwx+vAwMAa273yyitas2aN1q5dq2uvvVY5OTlKTk6W1WrVuHHjHO0sFudVH4ZhVDv3Y7VpU1e1SiJyc3O9+kMBAGgMvLXZVFhYmFMSYeaRRx7Ro48+qjvuuEOSlJCQoCNHjmju3LkaN26cYmJiJJ2vNrRt29bRr6CgwFGdiImJUUVFhQoLC52qEQUFBerdu7fb76Umbs+JqKio0KFDh1RVVeXNeAAAaDgMLxx1cO7cOTVr5vzV3Lx5c8cSz7i4OMXExCgzM9NxvaKiQtu2bXMkCImJifL393dqc+LECe3fv9/rSUSdV2ecO3dOkydP1qpVqyRJX3zxheLj4zVlyhRZrVY9+uijXg0QAIBLxbBhwzRnzhy1b99e1157rfbt26cFCxbo7rvvlnR+GCM5OVlpaWnq1KmTOnXqpLS0NLVo0UJjxoyRJIWHh2v8+PGaOnWqIiMjFRERoWnTpikhIcGxWsNb6pxEzJw5U59++qk++OAD3XrrrY7z/fv31+zZs0kiAABNiOX7w5P+tbd48WI9/vjjmjRpkgoKCmS1WnXffffpiSeecLSZPn26SktLNWnSJBUWFqpXr17avHmzQkNDHW0WLlwoPz8/jR49WqWlperXr58yMjLUvHlzD95LdRbDqNt+Wh06dNArr7yiG2+8UaGhofr0008VHx+vw4cPq0ePHiouLvZqgN5WXFys8PBwFX4Rr7BQVriiaRocf6OvQwDqTZVRoffLXlVRUVGt5hm448J3RezSVDULDnL7PvbSMuXdn1qvsfpSnb9FT548qaioqGrnS0pKvD7rEwAANFx1TiJuuOEG/b//9/8cry8kDitWrFBSUpL3IgMAwNcu8sTKxqbOcyLmzp2rW2+9VZ9//rmqqqr0zDPP6MCBA9q5c6e2bdtWHzECAOAbPMXTpTpXInr37q2PP/5Y586d0xVXXKHNmzcrOjpaO3fuVGJiYn3ECAAAGiC3HsCVkJDgWOIJAEBT5c7jvH/cvylzK4mw2Wxav369Dh48KIvFoi5dumjEiBHy8+OhoACAJuQiP8Wzsanzt/7+/fs1YsQI5efnq3PnzpLObzjVpk0bvf3220pISPB6kAAAoOGp85yIe+65R9dee62OHTumvXv3au/evcrLy9N1112ne++9tz5iBADANy5MrPTkaMLqXIn49NNPlZWV5fRQj1atWmnOnDm64YYbvBocAAC+ZDHOH570b8rqXIno3Lmzvv3222rnCwoKdOWVV3olKAAAGgT2iXCpVklEcXGx40hLS9OUKVP02muv6dixYzp27Jhee+01JScna968efUdLwAAaCBqNZzRsmVLpy2tDcPQ6NGjHecuPH5j2LBhstls9RAmAAA+wGZTLtUqidi6dWt9xwEAQMPDEk+XapVE9OnTp77jAAAAjYzbu0OdO3dOR48eVUVFhdP56667zuOgAABoEKhEuFTnJOLkyZP6/e9/r3fffbfG68yJAAA0GSQRLtV5iWdycrIKCwu1a9cuBQcHa9OmTVq1apU6deqkt99+uz5iBAAADVCdKxHvv/++3nrrLd1www1q1qyZOnTooAEDBigsLExz587VbbfdVh9xAgBw8bE6w6U6VyJKSkoUFRUlSYqIiNDJkyclnX+y5969e70bHQAAPnRhx0pPjqbMrR0rDx06JEm6/vrrtXz5cn3zzTdatmyZ2rZt6/UAAQBAw1Tn4Yzk5GSdOHFCkjR79mwNGjRIL730kgICApSRkeHt+AAA8B0mVrpU5yTizjvvdPx39+7d9fXXX+tf//qX2rdvr9atW3s1OAAA0HC5vU/EBS1atFCPHj28EQsAAA2KRR4+xdNrkTRMtUoiUlJSan3DBQsWuB0MAABoPGqVROzbt69WN/vhQ7oauv+5KkF+Fn9fhwHUC792Eb4OAag3zezl0vGL9MNY4ukSD+ACAMAMEytdqvMSTwAAAMkLEysBAGiyqES4RBIBAIAJT3edZMdKAACAGlCJAADADMMZLrlViVi9erVuuukmWa1WHTlyRJKUnp6ut956y6vBAQDgU4YXjiaszknE0qVLlZKSoiFDhuj06dOy2WySpJYtWyo9Pd3b8QEAgAaqzknE4sWLtWLFCs2aNUvNmzd3nO/Zs6c+++wzrwYHAIAv8Shw1+o8JyI3N1fdu3evdj4wMFAlJSVeCQoAgAaBHStdqnMlIi4uTjk5OdXOv/vuu7rmmmu8ERMAAA0DcyJcqnMl4pFHHtEDDzygsrIyGYah3bt36+WXX9bcuXP117/+tT5iBAAADVCdk4jf//73qqqq0vTp03Xu3DmNGTNG7dq10zPPPKM77rijPmIEAMAn2GzKNbf2iZgwYYImTJigU6dOyW63KyoqyttxAQDge+wT4ZJHm021bt3aW3EAAIBGps5JRFxcnCwW89mmX331lUcBAQDQYHi6TJNKhLPk5GSn15WVldq3b582bdqkRx55xFtxAQDgewxnuFTnJOKhhx6q8fyzzz6rrKwsjwMCAACNg9ee4jl48GC9/vrr3rodAAC+xz4RLnntKZ6vvfaaIiIivHU7AAB8jiWertU5iejevbvTxErDMJSfn6+TJ0/queee82pwAACg4arzcMbIkSM1YsQIxzFq1CjNnj1b+/fv17333lsfMQIAcMn45ptv9Nvf/laRkZFq0aKFrr/+emVnZzuuG4ah1NRUWa1WBQcHq2/fvjpw4IDTPcrLyzV58mS1bt1aISEhGj58uI4dO+b1WOtUiaiqqlLHjh01aNAgxcTEeD0YAAAalIu8OqOwsFA33XSTbrnlFr377ruKiorSl19+qZYtWzrazJ8/XwsWLFBGRoauuuoq/elPf9KAAQN06NAhhYaGSjq/knLDhg1at26dIiMjNXXqVA0dOlTZ2dlOT+D2VJ2SCD8/P91///06ePCg1wIAAKChuthzIubNm6fY2Fi9+OKLjnMdO3Z0/LdhGEpPT9esWbM0atQoSdKqVasUHR2ttWvX6r777lNRUZFWrlyp1atXq3///pKkNWvWKDY2Vlu2bNGgQYPcf0M/UufhjF69emnfvn1eCwAAgKauuLjY6SgvL6+x3dtvv62ePXvqN7/5jaKiotS9e3etWLHCcT03N1f5+fkaOHCg41xgYKD69OmjHTt2SJKys7NVWVnp1MZqtapr166ONt5S54mVkyZN0tSpU3Xs2DElJiYqJCTE6fp1113nteAAAPA5L6ywiI2NdXo9e/ZspaamVmv31VdfaenSpUpJSdFjjz2m3bt3a8qUKQoMDNRdd92l/Px8SVJ0dLRTv+joaB05ckSSlJ+fr4CAALVq1apamwv9vaXWScTdd9+t9PR03X777ZKkKVOmOK5ZLBYZhiGLxSKbzebVAAEA8BkvzYnIy8tTWFiY43RgYGCNze12u3r27Km0tDRJ51dEHjhwQEuXLtVdd93laPfjx09c+A52GUot2tRVrZOIVatW6c9//rNyc3O9GgAAAE1dWFiYUxJhpm3btrrmmmucznXp0sWxmeOFRQ35+flq27ato01BQYGjOhETE6OKigoVFhY6VSMKCgrUu3dvj9/LD9V6ToRhnE+nOnTo4PIAAKCpuDCx0pOjLm666SYdOnTI6dwXX3zh+H6Ni4tTTEyMMjMzHdcrKiq0bds2R4KQmJgof39/pzYnTpzQ/v37vZ5E1GlOhLfLIAAANGgXeYnnww8/rN69eystLU2jR4/W7t279fzzz+v555+XdP57ODk5WWlpaerUqZM6deqktLQ0tWjRQmPGjJEkhYeHa/z48Zo6daoiIyMVERGhadOmKSEhwbFaw1vqlERcddVVP5lIfPfddx4FBADApeqGG27Q+vXrNXPmTD355JOKi4tTenq67rzzTkeb6dOnq7S0VJMmTVJhYaF69eqlzZs3O/aIkKSFCxfKz89Po0ePVmlpqfr166eMjAyv7hEhSRbjwjjFT2jWrJnS09MVHh7ust24ceO8Elh9KS4uVnh4uPpqhPws/r4OB6gXfu2svg4BqDdV9nJtOb5cRUVFtZpn4I4L3xVXTUtT88Agt+9jKy/TF08/Vq+x+lKdKhF33HGHoqKi6isWAAAalos8nNHY1HpiJfMhAADAD9W6ElHLUQ8AAJoOKhEu1TqJsNvt9RkHAAANzsV+dkZjU+dtrwEAuGRQiXCpzg/gAgAAkKhEAABgjkqESyQRAACYYE6EawxnAAAAt1CJAADADMMZLpFEAABgguEM1xjOAAAAbqESAQCAGYYzXCKJAADADEmESwxnAAAAt1CJAADAhOX7w5P+TRlJBAAAZhjOcIkkAgAAEyzxdI05EQAAwC1UIgAAMMNwhkskEQAAuNLEEwFPMJwBAADcQiUCAAATTKx0jSQCAAAzzIlwieEMAADgFioRAACYYDjDNZIIAADMMJzhEsMZAADALVQiAAAwwXCGayQRAACYYTjDJZIIAADMkES4xJwIAADgFioRAACYYE6EayQRAACYYTjDJYYzAACAW6hEAABgwmIYshjulxM86dsYkEQAAGCG4QyXGM4AAABuoRIBAIAJVme4RhIBAIAZhjNcYjgDAAC4hUoEAAAmGM5wjSQCAAAzDGe4RBIBAIAJKhGuMScCAAC4hUoEAABmGM5wiUoEAAAuXBjScOfw1Ny5c2WxWJScnOw4ZxiGUlNTZbVaFRwcrL59++rAgQNO/crLyzV58mS1bt1aISEhGj58uI4dO+Z5QD9CEgEAQAO0Z88ePf/887ruuuuczs+fP18LFizQkiVLtGfPHsXExGjAgAE6c+aMo01ycrLWr1+vdevWafv27Tp79qyGDh0qm83m1RhJIgAAMGMYnh9uOHv2rO68806tWLFCrVq1+kE4htLT0zVr1iyNGjVKXbt21apVq3Tu3DmtXbtWklRUVKSVK1fqL3/5i/r376/u3btrzZo1+uyzz7Rlyxav/FouIIkAAMCEJ0MZPxzSKC4udjrKy8td/twHHnhAt912m/r37+90Pjc3V/n5+Ro4cKDjXGBgoPr06aMdO3ZIkrKzs1VZWenUxmq1qmvXro423kISAQBAPYuNjVV4eLjjmDt3rmnbdevWae/evTW2yc/PlyRFR0c7nY+OjnZcy8/PV0BAgFMF48dtvIXVGQAAmPHS6oy8vDyFhYU5TgcGBtbYPC8vTw899JA2b96soKAg09taLBbnH2MY1c5VC6UWbeqKSgQAACYsds8PSQoLC3M6zJKI7OxsFRQUKDExUX5+fvLz89O2bdu0aNEi+fn5OSoQP64oFBQUOK7FxMSooqJChYWFpm28hSQCAIAGol+/fvrss8+Uk5PjOHr27Kk777xTOTk5io+PV0xMjDIzMx19KioqtG3bNvXu3VuSlJiYKH9/f6c2J06c0P79+x1tvIXhDNSL2x/8Vnc/lq/1K1pr2ex2kqSbBp/WkLH/UafrShUeYdP9A67SVweCfRwpULNru3+nX439SldeXazINuV6aloP7dpW819xD87cr8Gj8vT8gqv11stxkqTLwir023sPq/uNp9Q6ulTFpwO064NorV7WSedK/C/mW4EnLvJmU6GhoeratavTuZCQEEVGRjrOJycnKy0tTZ06dVKnTp2UlpamFi1aaMyYMZKk8PBwjR8/XlOnTlVkZKQiIiI0bdo0JSQkVJuo6SmSCHjdVd3Oachvv9NXB5zH84Ja2PX5nhB99E5LPfy09zc9AbwpKNim3C/CtGXD5Zo1f59puxv7fKvOXU/rVIFzeTqyTbki2pRp5TOddfSryxTVtkwPPrpfEW3KNPfRHvUdPrykIT47Y/r06SotLdWkSZNUWFioXr16afPmzQoNDXW0Wbhwofz8/DR69GiVlpaqX79+ysjIUPPmzb0ai0+HMz788EMNGzZMVqtVFotFb7755k/22bZtmxITExUUFKT4+HgtW7as/gNFrQW1sGnGkiNKf+RynSly/rC+93qEXloYo30fhpr0BhqO7B1ttHrZVdqxNca0TWSbMt3/yAH93+PdZKty/uf0yJehSpvRQ7s/ilb+NyH6Z1ak/rb0KvW6uUDNmtvrO3x4i4/2ifihDz74QOnp6Y7XFotFqampOnHihMrKyrRt27Zq1YugoCAtXrxY//nPf3Tu3Dlt2LBBsbGxHsfyYz5NIkpKStStWzctWbKkVu1zc3M1ZMgQ3Xzzzdq3b58ee+wxTZkyRa+//no9R4raejDtG+1+L0z7PiJRQNNmsRia+sdP9fqaeB39qnaf9xaXVelciZ/sNqajoWnw6XDG4MGDNXjw4Fq3X7Zsmdq3b+/IyLp06aKsrCw9/fTT+tWvflVjn/LycqdNPYqLiz2KGeb6jCjUlQmlmjykk69DAerdr8d9JZvNorfXdahV+9DwCv3v+MN694329RwZvKkhDmc0JI0qHd65c6fTDlySNGjQIGVlZamysrLGPnPnznXa4KM+yjmQ2lgrdP+TxzV/cntVljeqjxVQZ1deXaQRd3ythX+8TtJPr7sPDqlU6sIsHc29TGtXXFn/AcJ7DC8cTVijmliZn59f4y5dVVVVOnXqlNq2bVutz8yZM5WSkuJ4XVxcTCJRD668rlSt2lRpyaYvHOea+0kJN5Zo+O9PaWjH62S3e3eTE8BXru3+ncJbVShjwweOc839DI1/6F8acccR3T2ir+N8cIsqPbUoS2WlfvrTIz1kYygDTUijSiKkmnfpqun8BYGBgaabesB7cj66TPfecpXTuakL85R3OEivPtuGBAJNyvsb2ylnd2unc08u2qOt77ZT5oZ2jnPBIZV6alGWKiub6cmURFVWeHdmPOofwxmuNaokIiYmpsZduvz8/BQZGemjqCBJpSXNdeSQ854PZeea6Uzhf8+HtqxSm3aViow+P/QUe0WZJKmwwE+FJ1k3j4YlKLhK1thzjtcx1nOKv6pYZ4r8dfLbYJ0pCnBqb6tqpsL/BOibI5dJOl+B+NPiPQoMsuvpJ65Ti8uq1OKyKklSUWEAiXVj4ekKCy+szmjIGlUSkZSUpA0bNjid27x5s3r27Cl/f76EGrobBxZrWnqe4/Vjy45Kklb/JVpr/mK+jA7whU5divTn5bsdryek/EuStOWddt/PhXDtyquLdHVCkSRp5ZsfOl37/fA+KjjRwovRAr7h0yTi7NmzOnz4sON1bm6ucnJyFBERofbt22vmzJn65ptv9Le//U2SNHHiRC1ZskQpKSmaMGGCdu7cqZUrV+rll1/21VuAC9N/7TyBLPPVCGW+GuGjaIC6+WxvpG67ofarx344D8Kd/miYGM5wzadJRFZWlm655RbH6wsTIMeNG6eMjAydOHFCR48edVyPi4vTxo0b9fDDD+vZZ5+V1WrVokWLTJd3AgDgkYu87XVj49Mkom/fvo6JkTXJyMiodq5Pnz7au3dvPUYFAABqo1HNiQAA4GJiOMM1kggAAMzYjfOHJ/2bMJIIAADMMCfCJbZOAwAAbqESAQCACYs8nBPhtUgaJpIIAADMsGOlSwxnAAAAt1CJAADABEs8XSOJAADADKszXGI4AwAAuIVKBAAAJiyGIYsHkyM96dsYkEQAAGDG/v3hSf8mjOEMAADgFioRAACYYDjDNZIIAADMsDrDJZIIAADMsGOlS8yJAAAAbqESAQCACXasdI0kAgAAMwxnuMRwBgAAcAuVCAAATFjs5w9P+jdlJBEAAJhhOMMlhjMAAIBbqEQAAGCGzaZcIokAAMAE2167xnAGAABwC5UIAADMMLHSJZIIAADMGJI8WabZtHMIkggAAMwwJ8I15kQAAAC3UIkAAMCMIQ/nRHgtkgaJJAIAADNMrHSJ4QwAAOAWKhEAAJixS7J42L8JI4kAAMAEqzNcYzgDAAC4hSQCAAAzFyZWenLUwdy5c3XDDTcoNDRUUVFRGjlypA4dOvSjkAylpqbKarUqODhYffv21YEDB5zalJeXa/LkyWrdurVCQkI0fPhwHTt2zONfx4+RRAAAYOYiJxHbtm3TAw88oF27dikzM1NVVVUaOHCgSkpKHG3mz5+vBQsWaMmSJdqzZ49iYmI0YMAAnTlzxtEmOTlZ69ev17p167R9+3adPXtWQ4cOlc1m89qvRmJOBAAADcamTZucXr/44ouKiopSdna2fvGLX8gwDKWnp2vWrFkaNWqUJGnVqlWKjo7W2rVrdd9996moqEgrV67U6tWr1b9/f0nSmjVrFBsbqy1btmjQoEFei5dKBAAAZrxUiSguLnY6ysvLa/Xji4qKJEkRERGSpNzcXOXn52vgwIGONoGBgerTp4927NghScrOzlZlZaVTG6vVqq5duzraeAtJBAAAZuxeOCTFxsYqPDzcccydO/cnf7RhGEpJSdHPf/5zde3aVZKUn58vSYqOjnZqGx0d7biWn5+vgIAAtWrVyrSNtzCcAQCACW8t8czLy1NYWJjjfGBg4E/2ffDBB/XPf/5T27dvr35fi/PmFYZhVDv3Y7VpU1dUIgAAqGdhYWFOx08lEZMnT9bbb7+trVu36vLLL3ecj4mJkaRqFYWCggJHdSImJkYVFRUqLCw0beMtJBEAAJi5yKszDMPQgw8+qDfeeEPvv/++4uLinK7HxcUpJiZGmZmZjnMVFRXatm2bevfuLUlKTEyUv7+/U5sTJ05o//79jjbewnAGAABm7IZk8WDXSXvd+j7wwANau3at3nrrLYWGhjoqDuHh4QoODpbFYlFycrLS0tLUqVMnderUSWlpaWrRooXGjBnjaDt+/HhNnTpVkZGRioiI0LRp05SQkOBYreEtJBEAADQQS5culST17dvX6fyLL76o3/3ud5Kk6dOnq7S0VJMmTVJhYaF69eqlzZs3KzQ01NF+4cKF8vPz0+jRo1VaWqp+/fopIyNDzZs392q8FsNo4ht7/0hxcbHCw8PVVyPkZ/H3dThAvfBrZ/V1CEC9qbKXa8vx5SoqKnKarOhNF74r+sc/JL/mPz0J0kyVrVxbvnqmXmP1JSoRAACYqvu8hmr9mzAmVgIAALdQiQAAwIwbKyyq9W/CSCIAADBjN+TRkEQdV2c0NgxnAAAAt1CJAADAjGE/f3jSvwkjiQAAwAxzIlwiiQAAwAxzIlxiTgQAAHALlQgAAMwwnOESSQQAAGYMeZhEeC2SBonhDAAA4BYqEQAAmGE4wyWSCAAAzNjtkjzY68HetPeJYDgDAAC4hUoEAABmGM5wiSQCAAAzJBEuMZwBAADcQiUCAAAzbHvtEkkEAAAmDMMuw4MncXrStzEgiQAAwIxheFZNYE4EAABAdVQiAAAwY3g4J6KJVyJIIgAAMGO3SxYP5jU08TkRDGcAAAC3UIkAAMAMwxkukUQAAGDCsNtleDCc0dSXeDKcAQAA3EIlAgAAMwxnuEQSAQCAGbshWUgizDCcAQAA3EIlAgAAM4YhyZN9Ipp2JYIkAgAAE4bdkOHBcIZBEgEAwCXKsMuzSgRLPAEAAKqhEgEAgAmGM1wjiQAAwAzDGS5dcknEhaywSpUe7R8CNGj2cl9HANSbKnuFpIvzV76n3xVVqvReMA3QJZdEnDlzRpK0XRt9HAlQj477OgCg/p05c0bh4eH1cu+AgADFxMRoe77n3xUxMTEKCAjwQlQNj8Vo6gM2P2K323X8+HGFhobKYrH4OpxLQnFxsWJjY5WXl6ewsDBfhwN4HZ/xi8swDJ05c0ZWq1XNmtXf+oCysjJVVFR4fJ+AgAAFBQV5IaKG55KrRDRr1kyXX365r8O4JIWFhfEPLJo0PuMXT31VIH4oKCioyX75ewtLPAEAgFtIIgAAgFtIIlDvAgMDNXv2bAUGBvo6FKBe8BnHpeqSm1gJAAC8g0oEAABwC0kEAABwC0kEAABwC0kEAABwC0kEvOK5555TXFycgoKClJiYqI8++shl+23btikxMVFBQUGKj4/XsmXLLlKkQN18+OGHGjZsmKxWqywWi958882f7MPnG5cKkgh47JVXXlFycrJmzZqlffv26eabb9bgwYN19OjRGtvn5uZqyJAhuvnmm7Vv3z499thjmjJlil5//fWLHDnw00pKStStWzctWbKkVu35fONSwhJPeKxXr17q0aOHli5d6jjXpUsXjRw5UnPnzq3WfsaMGXr77bd18OBBx7mJEyfq008/1c6dOy9KzIA7LBaL1q9fr5EjR5q24fONSwmVCHikoqJC2dnZGjhwoNP5gQMHaseOHTX22blzZ7X2gwYNUlZWliorm/Zjc9H08fnGpYQkAh45deqUbDaboqOjnc5HR0crPz+/xj75+fk1tq+qqtKpU6fqLVbgYuDzjUsJSQS84sePVTcMw+Wj1mtqX9N5oDHi841LBUkEPNK6dWs1b968WtWhoKCg2l9jF8TExNTY3s/PT5GRkfUWK3Ax8PnGpYQkAh4JCAhQYmKiMjMznc5nZmaqd+/eNfZJSkqq1n7z5s3q2bOn/P396y1W4GLg841LCUkEPJaSkqK//vWveuGFF3Tw4EE9/PDDOnr0qCZOnChJmjlzpu666y5H+4kTJ+rIkSNKSUnRwYMH9cILL2jlypWaNm2ar94CYOrs2bPKyclRTk6OpPNLOHNychxLmPl845JmAF7w7LPPGh06dDACAgKMHj16GNu2bXNcGzdunNGnTx+n9h988IHRvXt3IyAgwOjYsaOxdOnSixwxUDtbt241JFU7xo0bZxgGn29c2tgnAgAAuIXhDAAA4BaSCAAA4BaSCAAA4BaSCAAA4BaSCAAA4BaSCAAA4BaSCAAA4BaSCAAA4BaSCMAHUlNTdf311zte/+53v9PIkSMvehxff/21LBaLY0vnmnTs2FHp6em1vmdGRoZatmzpcWwWi0Vvvvmmx/cBUH9IIoDv/e53v5PFYpHFYpG/v7/i4+M1bdo0lZSU1PvPfuaZZ5SRkVGrtrX54geAi8HP1wEADcmtt96qF198UZWVlfroo490zz33qKSkREuXLq3WtrKy0mtPZQwPD/fKfQDgYqISAfxAYGCgYmJiFBsbqzFjxujOO+90lNQvDEG88MILio+PV2BgoAzDUFFRke69915FRUUpLCxMv/zlL/Xpp5863ffPf/6zoqOjFRoaqvHjx6usrMzp+o+HM+x2u+bNm6crr7xSgYGBat++vebMmSNJiouLkyR1795dFotFffv2dfR78cUX1aVLFwUFBenqq6/Wc8895/Rzdu/ere7duysoKEg9e/bUvn376vw7WrBggRISEhQSEqLY2FhNmjRJZ8+erdbuzTff1FVXXaWgoCANGDBAeXl5Ttc3bNigxMREBQUFKT4+Xn/84x9VVVVV53gA+A5JBOBCcHCwKisrHa8PHz6sV199Va+//rpjOOG2225Tfn6+Nm7cqOzsbPXo0UP9+vXTd999J0l69dVXNXv2bM2ZM0dZWVlq27ZttS/3H5s5c6bmzZunxx9/XJ9//rnWrl2r6OhoSecTAUnasmWLTpw4oTfeeEOStGLFCs2aNUtz5szRwYMHlZaWpscff1yrVq2SJJWUlGjo0KHq3LmzsrOzlZqa6tbjqZs1a6ZFixZp//79WrVqld5//31Nnz7dqc25c+c0Z84crVq1Sh9//LGKi4t1xx13OK7/4x//0G9/+1tNmTJFn3/+uZYvX66MjAxHogSgkfDxU0SBBmPcuHHGiBEjHK8/+eQTIzIy0hg9erRhGIYxe/Zsw9/f3ygoKHC0ee+994ywsDCjrKzM6V5XXHGFsXz5csMwDCMpKcmYOHGi0/VevXoZ3bp1q/FnFxcXG4GBgcaKFStqjDM3N9eQZOzbt8/pfGxsrLF27Vqnc0899ZSRlJRkGIZhLF++3IiIiDBKSkoc15cuXVrjvX6oQ4cOxsKFC02vv/rqq0ZkZKTj9YsvvmhIMnbt2uU4d/DgQUOS8cknnxiGYRg333yzkZaW5nSf1atXG23btnW8lmSsX7/e9OcC8D3mRAA/8M477+iyyy5TVVWVKisrNWLECC1evNhxvUOHDmrTpo3jdXZ2ts6ePavIyEin+5SWlurLL7+UJB08eFATJ050up6UlKStW7fWGMPBgwdVXl6ufv361TrukydPKi8vT+PHj9eECRMc56uqqhzzLQ4ePKhu3bqpRYsWTnHU1datW5WWlqbPP/9cxcXFqqqqUllZmUpKShQSEiJJ8vPzU8+ePR19rr76arVs2VIHDx7Uz372M2VnZ2vPnj1OlQebzaaysjKdO3fOKUYADRdJBPADt9xyi5YuXSp/f39ZrdZqEycvfEleYLfb1bZtW33wwQfV7uXuMsfg4OA697Hb7ZLOD2n06tXL6Vrz5s0lSYZhuBXPDx05ckRDhgzRxIkT9dRTTykiIkLbt2/X+PHjnYZ9pPNLNH/swjm73a4//vGPGjVqVLU2QUFBHscJ4OIgiQB+ICQkRFdeeWWt2/fo0UP5+fny8/NTx44da2zTpUsX7dq1S3fddZfj3K5du0zv2alTJwUHB+u9997TPffcU+16QECApPN/uV8QHR2tdu3a6auvvtKdd95Z432vueYarV69WqWlpY5ExVUcNcnKylJVVZX+8pe/qFmz81OqXn311WrtqqqqlJWVpZ/97GeSpEOHDun06dO6+uqrJZ3/vR06dKhOv2sADQ9JBOCB/v37KykpSSNHjtS8efPUuXNnHT9+XBs3btTIkSPVs2dPPfTQQxo3bpx69uypn//853rppZd04MABxcfH13jPoKAgzZgxQ9OnT1dAQIBuuukmnTx5UgcOHND48eMVFRWl4OBgbdq0SZdffrmCgoIUHh6u1NRUTZkyRWFhYRo8eLDKy8uVlZWlwsJCpaSkaMyYMZo1a5bGjx+vP/zhD/r666/19NNP1+n9XnHFFaqqqtLixYs1bNgwffzxx1q2bFm1dv7+/po8ebIWLVokf39/Pfjgg7rxxhsdScUTTzyhoUOHKjY2Vr/5zW/UrFkz/fOf/9Rnn32mP/3pT3X/HwKAT7A6A/CAxWLRxo0b9Ytf/EJ33323rrrqKt1xxx36+uuvHaspbr/9dj3xxBOaMWOGEhMTdeTIEd1///0u7/v4449r6tSpeuKJJ9SlSxfdfvvtKigokHR+vsGiRYu0fPlyWa1WjRgxQpJ0zz336K9//asyMjKUkJCgPn36KCMjw7Ek9LLLLtOGDRv0+eefq3v37po1a5bmzZtXp/d7/fXXa8GCBZo3b566du2ql156SXPnzq3WrkWLFpoxY4bGjBmjpKQkBQcHa926dY7rgwYN0jvvvKPMzEzdcMMNuvHGG7VgwQJ16NChTvEA8C2L4Y2BUgAAcMmhEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANxCEgEAANzy/wFDJt8gH5FpjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927\n",
      "F1 Score: 0.7082294264339152\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='newton-cg')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver=\"newton-cg\", max_iter=1000)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1396   21]\n",
      " [ 131   52]]\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1092f32afc0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "F1 Score: 0.40624999999999994\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PCA and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df, y_df = remove_labels(df_norm, 'is_safe')\n",
    "pca = PCA(n_components=0.95)\n",
    "df_reduced = pca.fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de componentes: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de componentes:\", pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.DataFrame(df_reduced, columns=[\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\",\"c10\",\"c11\",\"c12\",\"c13\",\"c14\",\"c15\",\"c16\",\"c17\"])\n",
    "df_reduced[\"is_safe\"] = y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = remove_labels(train_set, 'is_safe')\n",
    "x_val, y_val = remove_labels(val_set, 'is_safe')\n",
    "x_test, y_test = remove_labels(test_set, 'is_safe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input((x_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,465</span> (25.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,465\u001b[0m (25.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,465</span> (25.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,465\u001b[0m (25.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.3391 - val_accuracy: 0.8937 - val_loss: 0.2615\n",
      "Epoch 2/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9208 - loss: 0.2091 - val_accuracy: 0.9074 - val_loss: 0.2303\n",
      "Epoch 3/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - accuracy: 0.9321 - loss: 0.1791 - val_accuracy: 0.9149 - val_loss: 0.2043\n",
      "Epoch 4/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.9363 - loss: 0.1702 - val_accuracy: 0.9218 - val_loss: 0.1863\n",
      "Epoch 5/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9435 - loss: 0.1425 - val_accuracy: 0.9174 - val_loss: 0.1880\n",
      "Epoch 6/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9474 - loss: 0.1344 - val_accuracy: 0.9293 - val_loss: 0.1795\n",
      "Epoch 7/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9517 - loss: 0.1208 - val_accuracy: 0.9212 - val_loss: 0.1869\n",
      "Epoch 8/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9499 - loss: 0.1177 - val_accuracy: 0.9268 - val_loss: 0.1687\n",
      "Epoch 9/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9592 - loss: 0.1108 - val_accuracy: 0.9325 - val_loss: 0.1790\n",
      "Epoch 10/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9584 - loss: 0.1083 - val_accuracy: 0.9306 - val_loss: 0.1723\n",
      "Epoch 11/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9538 - loss: 0.1129 - val_accuracy: 0.9393 - val_loss: 0.1607\n",
      "Epoch 12/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9623 - loss: 0.0924 - val_accuracy: 0.9375 - val_loss: 0.1605\n",
      "Epoch 13/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9603 - loss: 0.0951 - val_accuracy: 0.9312 - val_loss: 0.1612\n",
      "Epoch 14/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9561 - loss: 0.1070 - val_accuracy: 0.9293 - val_loss: 0.1829\n",
      "Epoch 15/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9580 - loss: 0.0973 - val_accuracy: 0.9275 - val_loss: 0.1807\n",
      "Epoch 16/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9619 - loss: 0.0892 - val_accuracy: 0.9318 - val_loss: 0.1683\n",
      "Epoch 17/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9658 - loss: 0.0791 - val_accuracy: 0.9243 - val_loss: 0.1905\n",
      "Epoch 18/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9757 - loss: 0.0715 - val_accuracy: 0.9337 - val_loss: 0.1893\n",
      "Epoch 19/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9668 - loss: 0.0857 - val_accuracy: 0.9250 - val_loss: 0.2068\n",
      "Epoch 20/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9666 - loss: 0.0809 - val_accuracy: 0.9306 - val_loss: 0.1855\n",
      "Epoch 21/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9692 - loss: 0.0754 - val_accuracy: 0.9312 - val_loss: 0.2001\n",
      "Epoch 22/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9700 - loss: 0.0691 - val_accuracy: 0.9256 - val_loss: 0.1906\n",
      "Epoch 23/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9718 - loss: 0.0721 - val_accuracy: 0.9275 - val_loss: 0.1938\n",
      "Epoch 24/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0577 - val_accuracy: 0.9331 - val_loss: 0.2000\n",
      "Epoch 25/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9765 - loss: 0.0578 - val_accuracy: 0.9262 - val_loss: 0.2044\n",
      "Epoch 26/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9772 - loss: 0.0626 - val_accuracy: 0.9275 - val_loss: 0.2157\n",
      "Epoch 27/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9815 - loss: 0.0565 - val_accuracy: 0.9293 - val_loss: 0.1830\n",
      "Epoch 28/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9775 - loss: 0.0587 - val_accuracy: 0.9231 - val_loss: 0.1936\n",
      "Epoch 29/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9805 - loss: 0.0473 - val_accuracy: 0.9237 - val_loss: 0.2303\n",
      "Epoch 30/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9837 - loss: 0.0523 - val_accuracy: 0.9237 - val_loss: 0.2430\n",
      "Epoch 31/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9809 - loss: 0.0503 - val_accuracy: 0.9218 - val_loss: 0.2289\n",
      "Epoch 32/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9822 - loss: 0.0488 - val_accuracy: 0.9231 - val_loss: 0.2426\n",
      "Epoch 33/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9817 - loss: 0.0429 - val_accuracy: 0.9231 - val_loss: 0.2549\n",
      "Epoch 34/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9855 - loss: 0.0410 - val_accuracy: 0.9199 - val_loss: 0.2747\n",
      "Epoch 35/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9855 - loss: 0.0411 - val_accuracy: 0.9225 - val_loss: 0.2699\n",
      "Epoch 36/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9901 - loss: 0.0312 - val_accuracy: 0.9250 - val_loss: 0.2584\n",
      "Epoch 37/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9879 - loss: 0.0337 - val_accuracy: 0.9212 - val_loss: 0.2534\n",
      "Epoch 38/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9892 - loss: 0.0362 - val_accuracy: 0.9187 - val_loss: 0.3469\n",
      "Epoch 39/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9892 - loss: 0.0330 - val_accuracy: 0.9256 - val_loss: 0.2566\n",
      "Epoch 40/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9909 - loss: 0.0307 - val_accuracy: 0.9218 - val_loss: 0.3197\n",
      "Epoch 41/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9881 - loss: 0.0316 - val_accuracy: 0.9218 - val_loss: 0.2637\n",
      "Epoch 42/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9929 - loss: 0.0251 - val_accuracy: 0.9262 - val_loss: 0.2867\n",
      "Epoch 43/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9895 - loss: 0.0312 - val_accuracy: 0.9243 - val_loss: 0.2780\n",
      "Epoch 44/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9922 - loss: 0.0264 - val_accuracy: 0.9237 - val_loss: 0.2763\n",
      "Epoch 45/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9956 - loss: 0.0190 - val_accuracy: 0.9237 - val_loss: 0.3048\n",
      "Epoch 46/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9936 - loss: 0.0226 - val_accuracy: 0.9199 - val_loss: 0.3440\n",
      "Epoch 47/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9916 - loss: 0.0262 - val_accuracy: 0.9256 - val_loss: 0.3457\n",
      "Epoch 48/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9953 - loss: 0.0185 - val_accuracy: 0.9212 - val_loss: 0.2975\n",
      "Epoch 49/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9969 - loss: 0.0169 - val_accuracy: 0.9187 - val_loss: 0.3796\n",
      "Epoch 50/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9955 - loss: 0.0191 - val_accuracy: 0.9231 - val_loss: 0.3267\n",
      "Epoch 51/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 0.9913 - loss: 0.0249 - val_accuracy: 0.9199 - val_loss: 0.3783\n",
      "Epoch 52/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.9206 - val_loss: 0.3409\n",
      "Epoch 53/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0161 - val_accuracy: 0.9237 - val_loss: 0.3374\n",
      "Epoch 54/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0129 - val_accuracy: 0.9181 - val_loss: 0.3899\n",
      "Epoch 55/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0250 - val_accuracy: 0.9206 - val_loss: 0.3689\n",
      "Epoch 56/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9954 - loss: 0.0205 - val_accuracy: 0.9168 - val_loss: 0.4278\n",
      "Epoch 57/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.9959 - loss: 0.0172 - val_accuracy: 0.9250 - val_loss: 0.3361\n",
      "Epoch 58/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9976 - loss: 0.0150 - val_accuracy: 0.9199 - val_loss: 0.3933\n",
      "Epoch 59/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9951 - loss: 0.0189 - val_accuracy: 0.9225 - val_loss: 0.3511\n",
      "Epoch 60/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9970 - loss: 0.0122 - val_accuracy: 0.9206 - val_loss: 0.4374\n",
      "Epoch 61/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9959 - loss: 0.0137 - val_accuracy: 0.9206 - val_loss: 0.3641\n",
      "Epoch 62/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9982 - loss: 0.0103 - val_accuracy: 0.9149 - val_loss: 0.4886\n",
      "Epoch 63/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9250 - val_loss: 0.3731\n",
      "Epoch 64/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.9174 - val_loss: 0.4799\n",
      "Epoch 65/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.9218 - val_loss: 0.3697\n",
      "Epoch 66/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.9231 - val_loss: 0.3874\n",
      "Epoch 67/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9212 - val_loss: 0.4230\n",
      "Epoch 68/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9951 - loss: 0.0140 - val_accuracy: 0.9231 - val_loss: 0.3975\n",
      "Epoch 69/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.9212 - val_loss: 0.4431\n",
      "Epoch 70/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9913 - loss: 0.0213 - val_accuracy: 0.9225 - val_loss: 0.4709\n",
      "Epoch 71/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9968 - loss: 0.0157 - val_accuracy: 0.9256 - val_loss: 0.4036\n",
      "Epoch 72/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9964 - loss: 0.0105 - val_accuracy: 0.9174 - val_loss: 0.4045\n",
      "Epoch 73/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9932 - loss: 0.0220 - val_accuracy: 0.9237 - val_loss: 0.4190\n",
      "Epoch 74/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9206 - val_loss: 0.4582\n",
      "Epoch 75/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9988 - loss: 0.0071 - val_accuracy: 0.9237 - val_loss: 0.4109\n",
      "Epoch 76/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9899 - loss: 0.0238 - val_accuracy: 0.9206 - val_loss: 0.4593\n",
      "Epoch 77/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9955 - loss: 0.0114 - val_accuracy: 0.9218 - val_loss: 0.4192\n",
      "Epoch 78/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.9225 - val_loss: 0.4494\n",
      "Epoch 79/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 0.9193 - val_loss: 0.4523\n",
      "Epoch 80/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 0.9206 - val_loss: 0.4675\n",
      "Epoch 81/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9250 - val_loss: 0.4689\n",
      "Epoch 82/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 0.9243 - val_loss: 0.4723\n",
      "Epoch 83/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.9243 - val_loss: 0.4706\n",
      "Epoch 84/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.9218 - val_loss: 0.4747\n",
      "Epoch 85/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9978 - loss: 0.0138 - val_accuracy: 0.9262 - val_loss: 0.4405\n",
      "Epoch 86/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9199 - val_loss: 0.4636\n",
      "Epoch 87/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9212 - val_loss: 0.5013\n",
      "Epoch 88/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9933 - loss: 0.0208 - val_accuracy: 0.9187 - val_loss: 0.4863\n",
      "Epoch 89/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.9237 - val_loss: 0.5034\n",
      "Epoch 90/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9970 - loss: 0.0125 - val_accuracy: 0.9250 - val_loss: 0.4601\n",
      "Epoch 91/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9985 - loss: 0.0066 - val_accuracy: 0.9287 - val_loss: 0.4739\n",
      "Epoch 92/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.9237 - val_loss: 0.4986\n",
      "Epoch 93/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9987 - loss: 0.0081 - val_accuracy: 0.9206 - val_loss: 0.4450\n",
      "Epoch 94/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9960 - loss: 0.0167 - val_accuracy: 0.9181 - val_loss: 0.5099\n",
      "Epoch 95/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9960 - loss: 0.0154 - val_accuracy: 0.9262 - val_loss: 0.5010\n",
      "Epoch 96/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.9193 - val_loss: 0.4787\n",
      "Epoch 97/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9953 - loss: 0.0161 - val_accuracy: 0.9268 - val_loss: 0.4767\n",
      "Epoch 98/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 0.9237 - val_loss: 0.4748\n",
      "Epoch 99/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.9218 - val_loss: 0.5212\n",
      "Epoch 100/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 0.9149 - val_loss: 0.5730\n",
      "Epoch 101/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.9218 - val_loss: 0.4645\n",
      "Epoch 102/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.9156 - val_loss: 0.4646\n",
      "Epoch 103/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.9206 - val_loss: 0.4943\n",
      "Epoch 104/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9967 - loss: 0.0120 - val_accuracy: 0.9193 - val_loss: 0.5790\n",
      "Epoch 105/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9929 - loss: 0.0214 - val_accuracy: 0.9231 - val_loss: 0.5395\n",
      "Epoch 106/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9982 - loss: 0.0081 - val_accuracy: 0.9199 - val_loss: 0.4959\n",
      "Epoch 107/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9225 - val_loss: 0.5056\n",
      "Epoch 108/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9983 - loss: 0.0066 - val_accuracy: 0.9231 - val_loss: 0.5041\n",
      "Epoch 109/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9954 - loss: 0.0120 - val_accuracy: 0.9199 - val_loss: 0.4620\n",
      "Epoch 110/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 0.9225 - val_loss: 0.5029\n",
      "Epoch 111/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9970 - loss: 0.0108 - val_accuracy: 0.9225 - val_loss: 0.4948\n",
      "Epoch 112/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9989 - loss: 0.0075 - val_accuracy: 0.9231 - val_loss: 0.4817\n",
      "Epoch 113/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9992 - loss: 0.0040 - val_accuracy: 0.9262 - val_loss: 0.5185\n",
      "Epoch 114/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9974 - loss: 0.0090 - val_accuracy: 0.9237 - val_loss: 0.5165\n",
      "Epoch 115/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9961 - loss: 0.0107 - val_accuracy: 0.9250 - val_loss: 0.5171\n",
      "Epoch 116/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.9256 - val_loss: 0.5494\n",
      "Epoch 117/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 0.9231 - val_loss: 0.4992\n",
      "Epoch 118/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.9156 - val_loss: 0.5309\n",
      "Epoch 119/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9968 - loss: 0.0123 - val_accuracy: 0.9199 - val_loss: 0.5172\n",
      "Epoch 120/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 0.9193 - val_loss: 0.5701\n",
      "Epoch 121/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9977 - loss: 0.0111 - val_accuracy: 0.9212 - val_loss: 0.5276\n",
      "Epoch 122/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.9231 - val_loss: 0.5025\n",
      "Epoch 123/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9243 - val_loss: 0.4993\n",
      "Epoch 124/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9225 - val_loss: 0.5249\n",
      "Epoch 125/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9955 - loss: 0.0127 - val_accuracy: 0.9231 - val_loss: 0.5115\n",
      "Epoch 126/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.9231 - val_loss: 0.5110\n",
      "Epoch 127/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.9218 - val_loss: 0.5234\n",
      "Epoch 128/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 0.9250 - val_loss: 0.5032\n",
      "Epoch 129/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9250 - val_loss: 0.5413\n",
      "Epoch 130/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.9231 - val_loss: 0.6729\n",
      "Epoch 131/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0174 - val_accuracy: 0.9250 - val_loss: 0.5596\n",
      "Epoch 132/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9218 - val_loss: 0.6172\n",
      "Epoch 133/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0054 - val_accuracy: 0.9174 - val_loss: 0.5276\n",
      "Epoch 134/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.9243 - val_loss: 0.5252\n",
      "Epoch 135/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0050 - val_accuracy: 0.9243 - val_loss: 0.5225\n",
      "Epoch 136/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9946 - loss: 0.0191 - val_accuracy: 0.9231 - val_loss: 0.5147\n",
      "Epoch 137/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9212 - val_loss: 0.5197\n",
      "Epoch 138/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9937 - loss: 0.0152 - val_accuracy: 0.9268 - val_loss: 0.5146\n",
      "Epoch 139/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9983 - loss: 0.0068 - val_accuracy: 0.9243 - val_loss: 0.5083\n",
      "Epoch 140/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9237 - val_loss: 0.6435\n",
      "Epoch 141/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9218 - val_loss: 0.5819\n",
      "Epoch 142/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9983 - loss: 0.0099 - val_accuracy: 0.9231 - val_loss: 0.5259\n",
      "Epoch 143/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.9243 - val_loss: 0.5113\n",
      "Epoch 144/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9187 - val_loss: 0.6282\n",
      "Epoch 145/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9971 - loss: 0.0126 - val_accuracy: 0.9193 - val_loss: 0.5205\n",
      "Epoch 146/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9237 - val_loss: 0.5384\n",
      "Epoch 147/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9973 - loss: 0.0099 - val_accuracy: 0.9250 - val_loss: 0.5729\n",
      "Epoch 148/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9243 - val_loss: 0.5008\n",
      "Epoch 149/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9250 - val_loss: 0.5327\n",
      "Epoch 150/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9268 - val_loss: 0.5416\n",
      "Epoch 151/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9965 - loss: 0.0093 - val_accuracy: 0.9225 - val_loss: 0.6484\n",
      "Epoch 152/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.9237 - val_loss: 0.5297\n",
      "Epoch 153/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.9243 - val_loss: 0.5480\n",
      "Epoch 154/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9268 - val_loss: 0.5683\n",
      "Epoch 155/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9218 - val_loss: 0.5388\n",
      "Epoch 156/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9989 - loss: 0.0060 - val_accuracy: 0.9268 - val_loss: 0.5719\n",
      "Epoch 157/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9960 - loss: 0.0170 - val_accuracy: 0.9225 - val_loss: 0.5897\n",
      "Epoch 158/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9966 - loss: 0.0117 - val_accuracy: 0.9199 - val_loss: 0.5861\n",
      "Epoch 159/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9268 - val_loss: 0.5654\n",
      "Epoch 160/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9969 - loss: 0.0084 - val_accuracy: 0.9237 - val_loss: 0.6065\n",
      "Epoch 161/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9225 - val_loss: 0.5490\n",
      "Epoch 162/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9206 - val_loss: 0.5318\n",
      "Epoch 163/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9962 - loss: 0.0106 - val_accuracy: 0.9237 - val_loss: 0.5984\n",
      "Epoch 164/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9965 - loss: 0.0121 - val_accuracy: 0.9268 - val_loss: 0.5403\n",
      "Epoch 165/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9256 - val_loss: 0.5291\n",
      "Epoch 166/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9984 - loss: 0.0074 - val_accuracy: 0.9237 - val_loss: 0.4967\n",
      "Epoch 167/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9250 - val_loss: 0.5745\n",
      "Epoch 168/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9984 - loss: 0.0077 - val_accuracy: 0.9268 - val_loss: 0.5445\n",
      "Epoch 169/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9980 - loss: 0.0086 - val_accuracy: 0.9256 - val_loss: 0.5505\n",
      "Epoch 170/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9231 - val_loss: 0.5914\n",
      "Epoch 171/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9243 - val_loss: 0.5598\n",
      "Epoch 172/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9218 - val_loss: 0.5580\n",
      "Epoch 173/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9231 - val_loss: 0.5966\n",
      "Epoch 174/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.9218 - val_loss: 0.6089\n",
      "Epoch 175/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9225 - val_loss: 0.6419\n",
      "Epoch 176/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9984 - loss: 0.0038 - val_accuracy: 0.9212 - val_loss: 0.6141\n",
      "Epoch 177/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.9256 - val_loss: 0.5782\n",
      "Epoch 178/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9243 - val_loss: 0.5496\n",
      "Epoch 179/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.9225 - val_loss: 0.5702\n",
      "Epoch 180/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9206 - val_loss: 0.5408\n",
      "Epoch 181/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9225 - val_loss: 0.5965\n",
      "Epoch 182/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9231 - val_loss: 0.5922\n",
      "Epoch 183/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9262 - val_loss: 0.5512\n",
      "Epoch 184/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9977 - loss: 0.0102 - val_accuracy: 0.9256 - val_loss: 0.5545\n",
      "Epoch 185/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.9262 - val_loss: 0.5653\n",
      "Epoch 186/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9959 - loss: 0.0118 - val_accuracy: 0.9268 - val_loss: 0.5858\n",
      "Epoch 187/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.9262 - val_loss: 0.5868\n",
      "Epoch 188/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9967 - loss: 0.0130 - val_accuracy: 0.9262 - val_loss: 0.5772\n",
      "Epoch 189/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9268 - val_loss: 0.5466\n",
      "Epoch 190/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9287 - val_loss: 0.5320\n",
      "Epoch 191/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9243 - val_loss: 0.5724\n",
      "Epoch 192/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9989 - loss: 0.0071 - val_accuracy: 0.9275 - val_loss: 0.5810\n",
      "Epoch 193/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.9268 - val_loss: 0.5594\n",
      "Epoch 194/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9262 - val_loss: 0.5928\n",
      "Epoch 195/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9262 - val_loss: 0.5486\n",
      "Epoch 196/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9262 - val_loss: 0.5651\n",
      "Epoch 197/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9262 - val_loss: 0.5776\n",
      "Epoch 198/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9979 - loss: 0.0081 - val_accuracy: 0.9225 - val_loss: 0.5909\n",
      "Epoch 199/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9225 - val_loss: 0.6402\n",
      "Epoch 200/200\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9225 - val_loss: 0.6459\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=200, batch_size=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "y_pred = np.rint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1376   41]\n",
      " [  69  114]]\n"
     ]
    }
   ],
   "source": [
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1092fd56d50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.931\n",
      "F1 Score: 0.6745562130177515\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
